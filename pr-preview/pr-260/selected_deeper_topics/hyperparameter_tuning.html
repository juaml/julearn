<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="6.4. Inspecting Models" href="model_inspect.html" /><link rel="prev" title="6.2. Cross-validation consistent Confound Removal" href="confound_removal.html" />

    <!-- Generated with Sphinx 7.2.6 and Furo 2023.09.10 -->
        <title>6.3. Hyperparameter Tuning - julearn documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=38fa36eb" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">julearn  documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><div class="sidebar-scroll"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/julearn_logo_it.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">julearn  documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">1. Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html#setup-suggestion">2. Setup suggestion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html#installing">3. Installing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html#optional-dependencies">4. Optional Dependencies</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../what_really_need_know/index.html">5. What you really need to know</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of 5. What you really need to know</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../what_really_need_know/cross_validation.html">5.1. Why cross validation?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../what_really_need_know/data.html">5.2. Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../what_really_need_know/pipeline.html">5.3. Model Building</a></li>
<li class="toctree-l2"><a class="reference internal" href="../what_really_need_know/model_evaluation.html">5.4. Model Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../what_really_need_know/model_comparison.html">5.5. Model Comparison</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">6. Selected deeper topics</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of 6. Selected deeper topics</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="target_transformers.html">6.1. Applying preprocessing to the target</a></li>
<li class="toctree-l2"><a class="reference internal" href="confound_removal.html">6.2. Cross-validation consistent Confound Removal</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">6.3. Hyperparameter Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_inspect.html">6.4. Inspecting Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_validation_splitter.html">6.5. Cross-validation splitters</a></li>
<li class="toctree-l2"><a class="reference internal" href="stacked_models.html">6.6. Stacking Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="CBPM.html">6.7. Connectome-based Predictive Modeling (CBPM)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../available_pipeline_steps.html">7. Overview of available Pipeline Steps</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../examples.html">8. Examples</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of 8. Examples</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/00_starting/index.html">8.1. Starting with <code class="docutils literal notranslate"><span class="pre">julearn</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of 8.1. Starting with julearn</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_starting/run_combine_pandas.html">Working with <code class="docutils literal notranslate"><span class="pre">pandas</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_starting/run_simple_binary_classification.html">Simple Binary Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_starting/run_grouped_cv.html">Grouped CV</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_starting/plot_cm_acc_multiclass.html">Multiclass Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_starting/plot_stratified_kfold_reg.html">Stratified K-fold CV for regression analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_starting/plot_example_regression.html">Regression Analysis</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/01_model_comparison/index.html">8.2. Model Comparison</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of 8.2. Model Comparison</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_model_comparison/plot_simple_model_comparison.html">Simple Model Comparison</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/02_inspection/index.html">8.3. Inspection</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of 8.3. Inspection</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_inspection/run_binary_inspect_folds.html">Inspecting the fold-wise predictions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_inspection/plot_inspect_random_forest.html">Inspecting Random Forest models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_inspection/plot_groupcv_inspect_svm.html">Inspecting SVM models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_inspection/plot_preprocess.html">Preprocessing with variance threshold, zscore and PCA</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/03_complex_models/index.html">8.4. Complex Models</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of 8.4. Complex Models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_complex_models/run_apply_to_target.html">Transforming target variable with z-score</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_complex_models/run_hyperparameter_tuning_bayessearch.html">Tuning Hyperparameters using Bayesian Search</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_complex_models/run_hyperparameter_multiple_grids.html">Tuning Multiple Hyperparameters Grids</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_complex_models/run_stacked_models.html">Stacking Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_complex_models/run_hyperparameter_tuning.html">Tuning Hyperparameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_complex_models/run_example_pca_featsets.html">Regression Analysis</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/04_confounds/index.html">8.5. Confounds</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of 8.5. Confounds</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_confounds/run_return_confounds.html">Return Confounds in Confound Removal</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_confounds/plot_confound_removal_classification.html">Confound Removal (model comparison)</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/05_customization/index.html">8.6. Customization</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of 8.6. Customization</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_customization/run_custom_scorers_regression.html">Custom Scoring Function for Regression</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">9. API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of 9. API Reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/main.html">9.1. Main API</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of 9.1. Main API</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.run_cross_validation.html">julearn.run_cross_validation</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/pipeline.html">9.2. Pipeline</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of 9.2. Pipeline</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.PipelineCreator.html">julearn.PipelineCreator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.TargetPipelineCreator.html">julearn.TargetPipelineCreator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.pipeline.JuTargetPipeline.html">julearn.pipeline.JuTargetPipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.pipeline.pipeline_creator.Step.html">julearn.pipeline.pipeline_creator.Step</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/model_selection.html">9.3. Model Selection</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of 9.3. Model Selection</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.model_selection.ContinuousStratifiedKFold.html">julearn.model_selection.ContinuousStratifiedKFold</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.model_selection.RepeatedContinuousStratifiedKFold.html">julearn.model_selection.RepeatedContinuousStratifiedKFold</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.model_selection.ContinuousStratifiedGroupKFold.html">julearn.model_selection.ContinuousStratifiedGroupKFold</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.model_selection.RepeatedContinuousStratifiedGroupKFold.html">julearn.model_selection.RepeatedContinuousStratifiedGroupKFold</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.model_selection.StratifiedBootstrap.html">julearn.model_selection.StratifiedBootstrap</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.model_selection.get_searcher.html">julearn.model_selection.get_searcher</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.model_selection.list_searchers.html">julearn.model_selection.list_searchers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.model_selection.register_searcher.html">julearn.model_selection.register_searcher</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.model_selection.reset_searcher_register.html">julearn.model_selection.reset_searcher_register</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/base.html">9.4. Base</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of 9.4. Base</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.base.JuBaseEstimator.html">julearn.base.JuBaseEstimator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.base.JuTransformer.html">julearn.base.JuTransformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.base.WrapModel.html">julearn.base.WrapModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.base.ColumnTypes.html">julearn.base.ColumnTypes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.base.ColumnTypesLike.html">julearn.base.ColumnTypesLike</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.base.change_column_type.html">julearn.base.change_column_type</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.base.get_column_type.html">julearn.base.get_column_type</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.base.make_type_selector.html">julearn.base.make_type_selector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.base.ensure_column_types.html">julearn.base.ensure_column_types</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/inspect.html">9.5. Inspect</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of 9.5. Inspect</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.inspect.Inspector.html">julearn.inspect.Inspector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.inspect.FoldsInspector.html">julearn.inspect.FoldsInspector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.inspect.preprocess.html">julearn.inspect.preprocess</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/models.html">9.6. Models</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of 9.6. Models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.models.list_models.html">julearn.models.list_models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.models.get_model.html">julearn.models.get_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.models.register_model.html">julearn.models.register_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.models.reset_model_register.html">julearn.models.reset_model_register</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/models.html#dynamic-selection-deslib">9.7. Dynamic Selection (DESLib)</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of 9.7. Dynamic Selection (DESLib)</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.models.dynamic.DynamicSelection.html">julearn.models.dynamic.DynamicSelection</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/scoring.html">9.8. Scoring</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of 9.8. Scoring</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.scoring.get_scorer.html">julearn.scoring.get_scorer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.scoring.list_scorers.html">julearn.scoring.list_scorers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.scoring.register_scorer.html">julearn.scoring.register_scorer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.scoring.reset_scorer_register.html">julearn.scoring.reset_scorer_register</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.scoring.check_scoring.html">julearn.scoring.check_scoring</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/scoring.html#module-julearn.scoring.metrics">9.9. Scoring Metrics</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of 9.9. Scoring Metrics</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.scoring.metrics.r_corr.html">julearn.scoring.metrics.r_corr</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.scoring.metrics.r2_corr.html">julearn.scoring.metrics.r2_corr</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/transformers.html">9.10. Transformers</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of 9.10. Transformers</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.DropColumns.html">julearn.transformers.DropColumns</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.ChangeColumnTypes.html">julearn.transformers.ChangeColumnTypes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.SetColumnTypes.html">julearn.transformers.SetColumnTypes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.FilterColumns.html">julearn.transformers.FilterColumns</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.CBPM.html">julearn.transformers.CBPM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.JuColumnTransformer.html">julearn.transformers.JuColumnTransformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.confound_remover.ConfoundRemover.html">julearn.transformers.confound_remover.ConfoundRemover</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.list_transformers.html">julearn.transformers.list_transformers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.get_transformer.html">julearn.transformers.get_transformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.register_transformer.html">julearn.transformers.register_transformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.reset_transformer_register.html">julearn.transformers.reset_transformer_register</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/transformers.html#module-julearn.transformers.target">9.11. Target Transformers</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of 9.11. Target Transformers</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.target.JuTransformedTargetModel.html">julearn.transformers.target.JuTransformedTargetModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.target.JuTargetTransformer.html">julearn.transformers.target.JuTargetTransformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.target.TargetConfoundRemover.html">julearn.transformers.target.TargetConfoundRemover</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.target.TransformedTargetWarning.html">julearn.transformers.target.TransformedTargetWarning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.target.get_target_transformer.html">julearn.transformers.target.get_target_transformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.target.list_target_transformers.html">julearn.transformers.target.list_target_transformers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.target.register_target_transformer.html">julearn.transformers.target.register_target_transformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.transformers.target.reset_target_transformer_register.html">julearn.transformers.target.reset_target_transformer_register</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/utils.html">9.12. Utils</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of 9.12. Utils</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.utils.logger.html">julearn.utils.logger</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.utils.configure_logging.html">julearn.utils.configure_logging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.utils.raise_error.html">julearn.utils.raise_error</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.utils.warn_with_log.html">julearn.utils.warn_with_log</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/utils.html#module-julearn.utils.typing">9.13. Typing</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle navigation of 9.13. Typing</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.utils.typing.JuEstimatorLike.html">julearn.utils.typing.JuEstimatorLike</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.utils.typing.EstimatorLike.html">julearn.utils.typing.EstimatorLike</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.utils.typing.EstimatorLikeFit1.html">julearn.utils.typing.EstimatorLikeFit1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.utils.typing.EstimatorLikeFit2.html">julearn.utils.typing.EstimatorLikeFit2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.utils.typing.EstimatorLikeFity.html">julearn.utils.typing.EstimatorLikeFity</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/prepare.html">9.14. Prepare</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle navigation of 9.14. Prepare</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.prepare.prepare_input_data.html">julearn.prepare.prepare_input_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.prepare.check_consistency.html">julearn.prepare.check_consistency</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/stats.html">9.15. Stats</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle navigation of 9.15. Stats</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.stats.corrected_ttest.html">julearn.stats.corrected_ttest</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/viz.html">9.16. Visualization</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><div class="visually-hidden">Toggle navigation of 9.16. Visualization</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/generated/julearn.viz.plot_scores.html">julearn.viz.plot_scores</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../configuration.html">10. Configuring <code class="docutils literal notranslate"><span class="pre">julearn</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">11. Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../maintaining.html">12. Maintaining</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">13. FAQs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../whats_new.html">14. What’s new</a></li>
</ul>

</div>
</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="hyperparameter-tuning">
<span id="sphx-glr-auto-examples-99-docs-run-hyperparameters-docs-py"></span><span id="hp-tuning"></span><h1><span class="section-number">6.3. </span>Hyperparameter Tuning<a class="headerlink" href="#hyperparameter-tuning" title="Link to this heading">#</a></h1>
<section id="parameters-vs-hyperparameters">
<h2>Parameters vs Hyperparameters<a class="headerlink" href="#parameters-vs-hyperparameters" title="Link to this heading">#</a></h2>
<p>Parameters are the values that define the model, and are learned from the data.
For example, the weights of a linear regression model are parameters. The
parameters of a model are learned during training and are not set by the user.</p>
<p>Hyperparameters are the values that define the model, but are not learned from
the data. For example, the regularization parameter <code class="docutils literal notranslate"><span class="pre">C</span></code> of a Support Vector
Machine (<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a>) model is a hyperparameter. The
hyperparameters of a model are set by the user before training and are not
learned during training.</p>
<p>Let’s see an example of a <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a> model with a regularization
parameter <code class="docutils literal notranslate"><span class="pre">C</span></code>. We will use the <code class="docutils literal notranslate"><span class="pre">iris</span></code> dataset, which is a dataset of
measurements of flowers.</p>
<p>We start by loading the dataset and setting the features and target
variables.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">seaborn</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>  <span class="c1"># To print in a pretty way</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;iris&quot;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="s2">&quot;species&quot;</span>
<span class="n">X_types</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;continuous&quot;</span><span class="p">:</span> <span class="n">X</span><span class="p">}</span>

<span class="c1"># The dataset has three kind of species. We will keep two to perform a binary</span>
<span class="c1"># classification.</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;species&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="s2">&quot;versicolor&quot;</span><span class="p">,</span> <span class="s2">&quot;virginica&quot;</span><span class="p">])]</span>
</pre></div>
</div>
<p>We can now use the <a class="reference internal" href="../api/generated/julearn.PipelineCreator.html#julearn.PipelineCreator" title="julearn.PipelineCreator"><code class="xref py py-class docutils literal notranslate"><span class="pre">PipelineCreator</span></code></a> to create a pipeline with a
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">RobustScaler</span></code></a> and a
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a>, with a regularization parameter <code class="docutils literal notranslate"><span class="pre">C</span></code> set to
<code class="docutils literal notranslate"><span class="pre">0.1</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">julearn.pipeline</span> <span class="kn">import</span> <span class="n">PipelineCreator</span>

<span class="n">creator</span> <span class="o">=</span> <span class="n">PipelineCreator</span><span class="p">(</span><span class="n">problem_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;zscore&quot;</span><span class="p">)</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;svm&quot;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">creator</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>2024-04-29 09:55:04,386 - julearn - INFO - Adding step zscore that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:04,386 - julearn - INFO - Step added
2024-04-29 09:55:04,386 - julearn - INFO - Adding step svm that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:04,386 - julearn - INFO - Setting hyperparameter C = 0.1
2024-04-29 09:55:04,386 - julearn - INFO - Step added
PipelineCreator:
  Step 0: zscore
    estimator:     StandardScaler()
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {}
  Step 1: svm
    estimator:     SVC(C=0.1)
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {}
</pre></div>
</div>
</section>
<section id="id1">
<h2>Hyperparameter Tuning<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>Since it is the user who sets the hyperparameters, it is important to choose
the right values. This is not always easy, and it is common to try different
values and see which one works best. This process is called <em>hyperparameter
tuning</em>.</p>
<p>Basically, hyperparameter tuning refers to testing several hyperparameter
values and choosing the one that works best.</p>
<p>For example, we can try different values for the regularization parameter
<code class="docutils literal notranslate"><span class="pre">C</span></code> of the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a> model and see which one works best.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">julearn</span> <span class="kn">import</span> <span class="n">run_cross_validation</span>

<span class="n">scores1</span> <span class="o">=</span> <span class="n">run_cross_validation</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">X_types</span><span class="o">=</span><span class="n">X_types</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">creator</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Score with C=0.1: </span><span class="si">{</span><span class="n">scores1</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">creator2</span> <span class="o">=</span> <span class="n">PipelineCreator</span><span class="p">(</span><span class="n">problem_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">creator2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;zscore&quot;</span><span class="p">)</span>
<span class="n">creator2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;svm&quot;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="n">scores2</span> <span class="o">=</span> <span class="n">run_cross_validation</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">X_types</span><span class="o">=</span><span class="n">X_types</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">creator2</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Score with C=0.01: </span><span class="si">{</span><span class="n">scores2</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>2024-04-29 09:55:04,387 - julearn - INFO - ==== Input Data ====
2024-04-29 09:55:04,387 - julearn - INFO - Using dataframe as input
2024-04-29 09:55:04,387 - julearn - INFO -      Features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:04,388 - julearn - INFO -      Target: species
2024-04-29 09:55:04,388 - julearn - INFO -      Expanded features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:04,388 - julearn - INFO -      X_types:{&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]}
2024-04-29 09:55:04,388 - julearn - INFO - ====================
2024-04-29 09:55:04,388 - julearn - INFO -
2024-04-29 09:55:04,389 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:04,389 - julearn - INFO - ====================
2024-04-29 09:55:04,389 - julearn - INFO -
2024-04-29 09:55:04,389 - julearn - INFO - = Data Information =
2024-04-29 09:55:04,389 - julearn - INFO -      Problem type: classification
2024-04-29 09:55:04,389 - julearn - INFO -      Number of samples: 100
2024-04-29 09:55:04,389 - julearn - INFO -      Number of features: 4
2024-04-29 09:55:04,389 - julearn - INFO - ====================
2024-04-29 09:55:04,389 - julearn - INFO -
2024-04-29 09:55:04,389 - julearn - INFO -      Number of classes: 2
2024-04-29 09:55:04,390 - julearn - INFO -      Target type: object
2024-04-29 09:55:04,390 - julearn - INFO -      Class distributions: species
versicolor    50
virginica     50
Name: count, dtype: int64
2024-04-29 09:55:04,390 - julearn - INFO - Using outer CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:04,390 - julearn - INFO - Binary classification problem detected.
/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(
Score with C=0.1: 0.8099999999999999
2024-04-29 09:55:04,433 - julearn - INFO - Adding step zscore that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:04,434 - julearn - INFO - Step added
2024-04-29 09:55:04,434 - julearn - INFO - Adding step svm that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:04,434 - julearn - INFO - Setting hyperparameter C = 0.01
2024-04-29 09:55:04,434 - julearn - INFO - Step added
2024-04-29 09:55:04,434 - julearn - INFO - ==== Input Data ====
2024-04-29 09:55:04,434 - julearn - INFO - Using dataframe as input
2024-04-29 09:55:04,434 - julearn - INFO -      Features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:04,434 - julearn - INFO -      Target: species
2024-04-29 09:55:04,434 - julearn - INFO -      Expanded features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:04,434 - julearn - INFO -      X_types:{&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]}
2024-04-29 09:55:04,435 - julearn - INFO - ====================
2024-04-29 09:55:04,435 - julearn - INFO -
2024-04-29 09:55:04,435 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:04,435 - julearn - INFO - ====================
2024-04-29 09:55:04,436 - julearn - INFO -
2024-04-29 09:55:04,436 - julearn - INFO - = Data Information =
2024-04-29 09:55:04,436 - julearn - INFO -      Problem type: classification
2024-04-29 09:55:04,436 - julearn - INFO -      Number of samples: 100
2024-04-29 09:55:04,436 - julearn - INFO -      Number of features: 4
2024-04-29 09:55:04,436 - julearn - INFO - ====================
2024-04-29 09:55:04,436 - julearn - INFO -
2024-04-29 09:55:04,436 - julearn - INFO -      Number of classes: 2
2024-04-29 09:55:04,436 - julearn - INFO -      Target type: object
2024-04-29 09:55:04,437 - julearn - INFO -      Class distributions: species
versicolor    50
virginica     50
Name: count, dtype: int64
2024-04-29 09:55:04,437 - julearn - INFO - Using outer CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:04,437 - julearn - INFO - Binary classification problem detected.
/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(
Score with C=0.01: 0.19
</pre></div>
</div>
<p>We can see that the model with <code class="docutils literal notranslate"><span class="pre">C=0.1</span></code> works better than the model with
<code class="docutils literal notranslate"><span class="pre">C=0.01</span></code>. However, to be sure that <code class="docutils literal notranslate"><span class="pre">C=0.1</span></code> is the best value, we should
try more values. And since this is only one hyperparameter, it is not that
difficult. But what if we have more hyperparameters? And what if we have
several steps in the pipeline (e.g. feature selection, PCA, etc.)?
This is a major problem: the more hyperparameters we have, the more
times we use the same data for training and testing. This usually gives an
optimistic estimation of the performance of the model.</p>
<p>To prevent this, we can use a technique called <em>nested cross-validation</em>.
That is, we use cross-validation to <em>tune the hyperparameters</em>, and then we
use cross-validation again to estimate the performance of the model using
the best hyperparameters set. It is called <em>nested</em> because we first split
the data into training and testing sets to estimate the model performance
(outer loop), and then we split the training set into two sets to tune the
hyperparameters (inner loop).</p>
<p><code class="docutils literal notranslate"><span class="pre">julearn</span></code> has a simple way to do hyperparameter tuning using nested cross-
validation. When we use a <a class="reference internal" href="../api/generated/julearn.PipelineCreator.html#julearn.PipelineCreator" title="julearn.PipelineCreator"><code class="xref py py-class docutils literal notranslate"><span class="pre">PipelineCreator</span></code></a> to create a pipeline,
we can set the hyperparameters we want to tune and the values we want to try.</p>
<p>For example, we can try different values for the regularization parameter
<code class="docutils literal notranslate"><span class="pre">C</span></code> of the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a> model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">creator</span> <span class="o">=</span> <span class="n">PipelineCreator</span><span class="p">(</span><span class="n">problem_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;zscore&quot;</span><span class="p">)</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;svm&quot;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">creator</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>2024-04-29 09:55:04,482 - julearn - INFO - Adding step zscore that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:04,482 - julearn - INFO - Step added
2024-04-29 09:55:04,482 - julearn - INFO - Adding step svm that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:04,482 - julearn - INFO - Tuning hyperparameter C = [0.01, 0.1, 1, 10]
2024-04-29 09:55:04,482 - julearn - INFO - Step added
PipelineCreator:
  Step 0: zscore
    estimator:     StandardScaler()
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {}
  Step 1: svm
    estimator:     SVC()
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {&#39;svm__C&#39;: [0.01, 0.1, 1, 10]}
</pre></div>
</div>
<p>As we can see above, the creator now shows that the <code class="docutils literal notranslate"><span class="pre">C</span></code> hyperparameter
will be tuned. We can now use this creator to run cross-validation. This will
tune the hyperparameters and estimate the performance of the model using the
best hyperparameters set.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scores_tuned</span><span class="p">,</span> <span class="n">model_tuned</span> <span class="o">=</span> <span class="n">run_cross_validation</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">X_types</span><span class="o">=</span><span class="n">X_types</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">creator</span><span class="p">,</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Scores with best hyperparameter: </span><span class="si">{</span><span class="n">scores_tuned</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>2024-04-29 09:55:04,483 - julearn - INFO - ==== Input Data ====
2024-04-29 09:55:04,483 - julearn - INFO - Using dataframe as input
2024-04-29 09:55:04,483 - julearn - INFO -      Features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:04,483 - julearn - INFO -      Target: species
2024-04-29 09:55:04,484 - julearn - INFO -      Expanded features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:04,484 - julearn - INFO -      X_types:{&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]}
2024-04-29 09:55:04,484 - julearn - INFO - ====================
2024-04-29 09:55:04,484 - julearn - INFO -
2024-04-29 09:55:04,485 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:04,485 - julearn - INFO - Tuning hyperparameters using grid
2024-04-29 09:55:04,485 - julearn - INFO - Hyperparameters:
2024-04-29 09:55:04,485 - julearn - INFO -      svm__C: [0.01, 0.1, 1, 10]
2024-04-29 09:55:04,485 - julearn - INFO - Using inner CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:04,485 - julearn - INFO - Search Parameters:
2024-04-29 09:55:04,486 - julearn - INFO -      cv: KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:04,486 - julearn - INFO - ====================
2024-04-29 09:55:04,486 - julearn - INFO -
2024-04-29 09:55:04,486 - julearn - INFO - = Data Information =
2024-04-29 09:55:04,486 - julearn - INFO -      Problem type: classification
2024-04-29 09:55:04,486 - julearn - INFO -      Number of samples: 100
2024-04-29 09:55:04,486 - julearn - INFO -      Number of features: 4
2024-04-29 09:55:04,486 - julearn - INFO - ====================
2024-04-29 09:55:04,486 - julearn - INFO -
2024-04-29 09:55:04,486 - julearn - INFO -      Number of classes: 2
2024-04-29 09:55:04,486 - julearn - INFO -      Target type: object
2024-04-29 09:55:04,487 - julearn - INFO -      Class distributions: species
versicolor    50
virginica     50
Name: count, dtype: int64
2024-04-29 09:55:04,487 - julearn - INFO - Using outer CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:04,487 - julearn - INFO - Binary classification problem detected.
/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(
2024-04-29 09:55:05,376 - julearn - INFO - Fitting final model
Scores with best hyperparameter: 0.9100000000000001
</pre></div>
</div>
<p>We can see that the model with the best hyperparameters works better than
the model with <code class="docutils literal notranslate"><span class="pre">C=0.1</span></code>. But what’s the best hyperparameter set? We can
see it by printing the <code class="docutils literal notranslate"><span class="pre">model_tuned.best_params_</span></code> variable.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pprint</span><span class="p">(</span><span class="n">model_tuned</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>{&#39;svm__C&#39;: 1}
</pre></div>
</div>
<p>We can see that the best hyperparameter set is <code class="docutils literal notranslate"><span class="pre">C=1</span></code>. Since this
hyperparameter was not on the boundary of the values we tried, we can
conclude that our search for the best <code class="docutils literal notranslate"><span class="pre">C</span></code> value was successful.</p>
<p>However, by checking the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a> documentation, we can
see that there are more hyperparameters that we can tune. For example, for
the default <code class="docutils literal notranslate"><span class="pre">rbf</span></code> kernel, we can tune the <code class="docutils literal notranslate"><span class="pre">gamma</span></code> hyperparameter:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">creator</span> <span class="o">=</span> <span class="n">PipelineCreator</span><span class="p">(</span><span class="n">problem_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;zscore&quot;</span><span class="p">)</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;svm&quot;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">gamma</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">creator</span><span class="p">)</span>

<span class="n">scores_tuned</span><span class="p">,</span> <span class="n">model_tuned</span> <span class="o">=</span> <span class="n">run_cross_validation</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">X_types</span><span class="o">=</span><span class="n">X_types</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">creator</span><span class="p">,</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Scores with best hyperparameter: </span><span class="si">{</span><span class="n">scores_tuned</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">model_tuned</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>2024-04-29 09:55:05,551 - julearn - INFO - Adding step zscore that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:05,551 - julearn - INFO - Step added
2024-04-29 09:55:05,551 - julearn - INFO - Adding step svm that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:05,551 - julearn - INFO - Tuning hyperparameter C = [0.01, 0.1, 1, 10]
2024-04-29 09:55:05,551 - julearn - INFO - Tuning hyperparameter gamma = [0.01, 0.1, 1, 10]
2024-04-29 09:55:05,552 - julearn - INFO - Step added
PipelineCreator:
  Step 0: zscore
    estimator:     StandardScaler()
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {}
  Step 1: svm
    estimator:     SVC()
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {&#39;svm__C&#39;: [0.01, 0.1, 1, 10], &#39;svm__gamma&#39;: [0.01, 0.1, 1, 10]}

2024-04-29 09:55:05,552 - julearn - INFO - ==== Input Data ====
2024-04-29 09:55:05,552 - julearn - INFO - Using dataframe as input
2024-04-29 09:55:05,552 - julearn - INFO -      Features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:05,552 - julearn - INFO -      Target: species
2024-04-29 09:55:05,552 - julearn - INFO -      Expanded features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:05,552 - julearn - INFO -      X_types:{&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]}
2024-04-29 09:55:05,553 - julearn - INFO - ====================
2024-04-29 09:55:05,553 - julearn - INFO -
2024-04-29 09:55:05,554 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:05,554 - julearn - INFO - Tuning hyperparameters using grid
2024-04-29 09:55:05,554 - julearn - INFO - Hyperparameters:
2024-04-29 09:55:05,554 - julearn - INFO -      svm__C: [0.01, 0.1, 1, 10]
2024-04-29 09:55:05,554 - julearn - INFO -      svm__gamma: [0.01, 0.1, 1, 10]
2024-04-29 09:55:05,554 - julearn - INFO - Using inner CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:05,554 - julearn - INFO - Search Parameters:
2024-04-29 09:55:05,554 - julearn - INFO -      cv: KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:05,554 - julearn - INFO - ====================
2024-04-29 09:55:05,554 - julearn - INFO -
2024-04-29 09:55:05,554 - julearn - INFO - = Data Information =
2024-04-29 09:55:05,555 - julearn - INFO -      Problem type: classification
2024-04-29 09:55:05,555 - julearn - INFO -      Number of samples: 100
2024-04-29 09:55:05,555 - julearn - INFO -      Number of features: 4
2024-04-29 09:55:05,555 - julearn - INFO - ====================
2024-04-29 09:55:05,555 - julearn - INFO -
2024-04-29 09:55:05,555 - julearn - INFO -      Number of classes: 2
2024-04-29 09:55:05,555 - julearn - INFO -      Target type: object
2024-04-29 09:55:05,555 - julearn - INFO -      Class distributions: species
versicolor    50
virginica     50
Name: count, dtype: int64
2024-04-29 09:55:05,556 - julearn - INFO - Using outer CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:05,556 - julearn - INFO - Binary classification problem detected.
/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(
2024-04-29 09:55:08,924 - julearn - INFO - Fitting final model
Scores with best hyperparameter: 0.9100000000000001
{&#39;svm__C&#39;: 10, &#39;svm__gamma&#39;: 0.01}
</pre></div>
</div>
<p>We can see that the best hyperparameter set is <code class="docutils literal notranslate"><span class="pre">C=1</span></code> and <code class="docutils literal notranslate"><span class="pre">gamma=0.1</span></code>.
But since <code class="docutils literal notranslate"><span class="pre">gamma</span></code> was on the boundary of the values we tried, we should
try more values to be sure that we are using the best hyperparameter set.</p>
<p>We can even give a combination of different variable types, like the words
<code class="docutils literal notranslate"><span class="pre">&quot;scale&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;auto&quot;</span></code> for the <code class="docutils literal notranslate"><span class="pre">gamma</span></code> hyperparameter:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">creator</span> <span class="o">=</span> <span class="n">PipelineCreator</span><span class="p">(</span><span class="n">problem_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;zscore&quot;</span><span class="p">)</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="s2">&quot;svm&quot;</span><span class="p">,</span>
    <span class="n">C</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="n">gamma</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">creator</span><span class="p">)</span>

<span class="n">scores_tuned</span><span class="p">,</span> <span class="n">model_tuned</span> <span class="o">=</span> <span class="n">run_cross_validation</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">X_types</span><span class="o">=</span><span class="n">X_types</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">creator</span><span class="p">,</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Scores with best hyperparameter: </span><span class="si">{</span><span class="n">scores_tuned</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">model_tuned</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>2024-04-29 09:55:09,603 - julearn - INFO - Adding step zscore that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:09,603 - julearn - INFO - Step added
2024-04-29 09:55:09,603 - julearn - INFO - Adding step svm that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:09,603 - julearn - INFO - Tuning hyperparameter C = [0.01, 0.1, 1, 10]
2024-04-29 09:55:09,603 - julearn - INFO - Tuning hyperparameter gamma = [1e-05, 0.0001, 0.001, 0.01, &#39;scale&#39;, &#39;auto&#39;]
2024-04-29 09:55:09,603 - julearn - INFO - Step added
PipelineCreator:
  Step 0: zscore
    estimator:     StandardScaler()
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {}
  Step 1: svm
    estimator:     SVC()
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {&#39;svm__C&#39;: [0.01, 0.1, 1, 10], &#39;svm__gamma&#39;: [1e-05, 0.0001, 0.001, 0.01, &#39;scale&#39;, &#39;auto&#39;]}

2024-04-29 09:55:09,604 - julearn - INFO - ==== Input Data ====
2024-04-29 09:55:09,604 - julearn - INFO - Using dataframe as input
2024-04-29 09:55:09,604 - julearn - INFO -      Features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:09,604 - julearn - INFO -      Target: species
2024-04-29 09:55:09,604 - julearn - INFO -      Expanded features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:09,604 - julearn - INFO -      X_types:{&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]}
2024-04-29 09:55:09,605 - julearn - INFO - ====================
2024-04-29 09:55:09,605 - julearn - INFO -
2024-04-29 09:55:09,605 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:09,605 - julearn - INFO - Tuning hyperparameters using grid
2024-04-29 09:55:09,605 - julearn - INFO - Hyperparameters:
2024-04-29 09:55:09,606 - julearn - INFO -      svm__C: [0.01, 0.1, 1, 10]
2024-04-29 09:55:09,606 - julearn - INFO -      svm__gamma: [1e-05, 0.0001, 0.001, 0.01, &#39;scale&#39;, &#39;auto&#39;]
2024-04-29 09:55:09,606 - julearn - INFO - Using inner CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:09,606 - julearn - INFO - Search Parameters:
2024-04-29 09:55:09,606 - julearn - INFO -      cv: KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:09,606 - julearn - INFO - ====================
2024-04-29 09:55:09,606 - julearn - INFO -
2024-04-29 09:55:09,606 - julearn - INFO - = Data Information =
2024-04-29 09:55:09,606 - julearn - INFO -      Problem type: classification
2024-04-29 09:55:09,606 - julearn - INFO -      Number of samples: 100
2024-04-29 09:55:09,606 - julearn - INFO -      Number of features: 4
2024-04-29 09:55:09,606 - julearn - INFO - ====================
2024-04-29 09:55:09,606 - julearn - INFO -
2024-04-29 09:55:09,606 - julearn - INFO -      Number of classes: 2
2024-04-29 09:55:09,606 - julearn - INFO -      Target type: object
2024-04-29 09:55:09,607 - julearn - INFO -      Class distributions: species
versicolor    50
virginica     50
Name: count, dtype: int64
2024-04-29 09:55:09,607 - julearn - INFO - Using outer CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:09,607 - julearn - INFO - Binary classification problem detected.
/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(
2024-04-29 09:55:14,484 - julearn - INFO - Fitting final model
Scores with best hyperparameter: 0.9100000000000001
{&#39;svm__C&#39;: 10, &#39;svm__gamma&#39;: 0.01}
</pre></div>
</div>
<p>We can even tune hyperparameters from different steps of the pipeline. Let’s
add a <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">SelectKBest</span></code></a> step to the pipeline
and tune its <code class="docutils literal notranslate"><span class="pre">k</span></code> hyperparameter:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">creator</span> <span class="o">=</span> <span class="n">PipelineCreator</span><span class="p">(</span><span class="n">problem_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;zscore&quot;</span><span class="p">)</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;select_k&quot;</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="s2">&quot;svm&quot;</span><span class="p">,</span>
    <span class="n">C</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="n">gamma</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">creator</span><span class="p">)</span>

<span class="n">scores_tuned</span><span class="p">,</span> <span class="n">model_tuned</span> <span class="o">=</span> <span class="n">run_cross_validation</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">X_types</span><span class="o">=</span><span class="n">X_types</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">creator</span><span class="p">,</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Scores with best hyperparameter: </span><span class="si">{</span><span class="n">scores_tuned</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">model_tuned</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>2024-04-29 09:55:15,461 - julearn - INFO - Adding step zscore that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:15,461 - julearn - INFO - Step added
2024-04-29 09:55:15,461 - julearn - INFO - Adding step select_k that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:15,461 - julearn - INFO - Tuning hyperparameter k = [2, 3, 4]
2024-04-29 09:55:15,461 - julearn - INFO - Step added
2024-04-29 09:55:15,461 - julearn - INFO - Adding step svm that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:15,461 - julearn - INFO - Tuning hyperparameter C = [0.01, 0.1, 1, 10]
2024-04-29 09:55:15,462 - julearn - INFO - Tuning hyperparameter gamma = [0.001, 0.01, 0.1, &#39;scale&#39;, &#39;auto&#39;]
2024-04-29 09:55:15,462 - julearn - INFO - Step added
PipelineCreator:
  Step 0: zscore
    estimator:     StandardScaler()
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {}
  Step 1: select_k
    estimator:     SelectKBest()
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {&#39;select_k__k&#39;: [2, 3, 4]}
  Step 2: svm
    estimator:     SVC()
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {&#39;svm__C&#39;: [0.01, 0.1, 1, 10], &#39;svm__gamma&#39;: [0.001, 0.01, 0.1, &#39;scale&#39;, &#39;auto&#39;]}

2024-04-29 09:55:15,462 - julearn - INFO - ==== Input Data ====
2024-04-29 09:55:15,462 - julearn - INFO - Using dataframe as input
2024-04-29 09:55:15,462 - julearn - INFO -      Features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:15,462 - julearn - INFO -      Target: species
2024-04-29 09:55:15,463 - julearn - INFO -      Expanded features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:15,463 - julearn - INFO -      X_types:{&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]}
2024-04-29 09:55:15,463 - julearn - INFO - ====================
2024-04-29 09:55:15,463 - julearn - INFO -
2024-04-29 09:55:15,464 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:15,464 - julearn - INFO - Tuning hyperparameters using grid
2024-04-29 09:55:15,464 - julearn - INFO - Hyperparameters:
2024-04-29 09:55:15,464 - julearn - INFO -      select_k__k: [2, 3, 4]
2024-04-29 09:55:15,464 - julearn - INFO -      svm__C: [0.01, 0.1, 1, 10]
2024-04-29 09:55:15,464 - julearn - INFO -      svm__gamma: [0.001, 0.01, 0.1, &#39;scale&#39;, &#39;auto&#39;]
2024-04-29 09:55:15,464 - julearn - INFO - Using inner CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:15,464 - julearn - INFO - Search Parameters:
2024-04-29 09:55:15,464 - julearn - INFO -      cv: KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:15,464 - julearn - INFO - ====================
2024-04-29 09:55:15,464 - julearn - INFO -
2024-04-29 09:55:15,465 - julearn - INFO - = Data Information =
2024-04-29 09:55:15,465 - julearn - INFO -      Problem type: classification
2024-04-29 09:55:15,465 - julearn - INFO -      Number of samples: 100
2024-04-29 09:55:15,465 - julearn - INFO -      Number of features: 4
2024-04-29 09:55:15,465 - julearn - INFO - ====================
2024-04-29 09:55:15,465 - julearn - INFO -
2024-04-29 09:55:15,465 - julearn - INFO -      Number of classes: 2
2024-04-29 09:55:15,465 - julearn - INFO -      Target type: object
2024-04-29 09:55:15,465 - julearn - INFO -      Class distributions: species
versicolor    50
virginica     50
Name: count, dtype: int64
2024-04-29 09:55:15,466 - julearn - INFO - Using outer CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:15,466 - julearn - INFO - Binary classification problem detected.
/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(
2024-04-29 09:55:31,248 - julearn - INFO - Fitting final model
Scores with best hyperparameter: 0.9100000000000001
{&#39;select_k__k&#39;: 4, &#39;svm__C&#39;: 10, &#39;svm__gamma&#39;: 0.01}
</pre></div>
</div>
<p>But how will <code class="docutils literal notranslate"><span class="pre">julearn</span></code> find the optimal hyperparameter set?</p>
</section>
<section id="searchers">
<h2>Searchers<a class="headerlink" href="#searchers" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">julearn</span></code> uses the same concept as <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> to tune hyperparameters:
it uses a <em>searcher</em> to find the best hyperparameter set. A searcher is an
object that receives a set of hyperparameters and their values, and then
tries to find the best combination of values for the hyperparameters using
cross-validation.</p>
<p>By default, <code class="docutils literal notranslate"><span class="pre">julearn</span></code> uses a
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a>.
This searcher, specified as <code class="docutils literal notranslate"><span class="pre">&quot;grid&quot;</span></code> is very simple. First, it constructs
the _grid_ of hyperparameters to try. As we see above, we have 3
hyperparameters to tune. So it constructs a 3-dimentional grid with all the
possible combinations of the hyperparameters values. The second step is to
perform cross-validation on each of the possible combinations of
hyperparameters values.</p>
<p>Other searchers that <code class="docutils literal notranslate"><span class="pre">julearn</span></code> provides are the
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code></a> and
<a class="reference external" href="https://scikit-optimize.readthedocs.io/en/latest/modules/generated/skopt.BayesSearchCV.html#skopt.BayesSearchCV" title="(in scikit-optimize v0.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">BayesSearchCV</span></code></a>.</p>
<p>The randomized searcher
(<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code></a>) is similar to the
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a>, but instead
of trying all the possible combinations of hyperparameter values, it tries
a random subset of them. This is useful when we have a lot of hyperparameters
to tune, since it can be very time consuming to try all the possible
combinations, as well as continuous parameters that can be sampled out of a
distribution. For more information, see the
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code></a> documentation.</p>
<p>The Bayesian searcher (<a class="reference external" href="https://scikit-optimize.readthedocs.io/en/latest/modules/generated/skopt.BayesSearchCV.html#skopt.BayesSearchCV" title="(in scikit-optimize v0.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">BayesSearchCV</span></code></a>) is a bit more
complex. It uses Bayesian optimization to find the best hyperparameter set.
As with the randomized search, it is useful when we have many
hyperparameters to tune, and we don’t want to try all the possible
combinations due to computational constraints. For more information, see the
<a class="reference external" href="https://scikit-optimize.readthedocs.io/en/latest/modules/generated/skopt.BayesSearchCV.html#skopt.BayesSearchCV" title="(in scikit-optimize v0.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">BayesSearchCV</span></code></a> documentation, including how to specify
the prior distributions of the hyperparameters.</p>
<p>We can specify the kind of searcher and its parametrization, by setting the
<code class="docutils literal notranslate"><span class="pre">search_params</span></code> parameter in the <a class="reference internal" href="../api/generated/julearn.run_cross_validation.html#julearn.run_cross_validation" title="julearn.run_cross_validation"><code class="xref py py-func docutils literal notranslate"><span class="pre">run_cross_validation()</span></code></a> function.
For example, we can use the
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code></a> searcher with
10 iterations of random search.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">search_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;kind&quot;</span><span class="p">:</span> <span class="s2">&quot;random&quot;</span><span class="p">,</span>
    <span class="s2">&quot;n_iter&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">scores_tuned</span><span class="p">,</span> <span class="n">model_tuned</span> <span class="o">=</span> <span class="n">run_cross_validation</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">X_types</span><span class="o">=</span><span class="n">X_types</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">creator</span><span class="p">,</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
    <span class="n">search_params</span><span class="o">=</span><span class="n">search_params</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Scores with best hyperparameter using 10 iterations of &quot;</span>
    <span class="sa">f</span><span class="s2">&quot;randomized search: </span><span class="si">{</span><span class="n">scores_tuned</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">model_tuned</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>2024-04-29 09:55:34,395 - julearn - INFO - ==== Input Data ====
2024-04-29 09:55:34,395 - julearn - INFO - Using dataframe as input
2024-04-29 09:55:34,395 - julearn - INFO -      Features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:34,395 - julearn - INFO -      Target: species
2024-04-29 09:55:34,395 - julearn - INFO -      Expanded features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:34,395 - julearn - INFO -      X_types:{&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]}
2024-04-29 09:55:34,395 - julearn - INFO - ====================
2024-04-29 09:55:34,395 - julearn - INFO -
2024-04-29 09:55:34,396 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:34,396 - julearn - INFO - Tuning hyperparameters using random
2024-04-29 09:55:34,396 - julearn - INFO - Hyperparameters:
2024-04-29 09:55:34,396 - julearn - INFO -      select_k__k: [2, 3, 4]
2024-04-29 09:55:34,396 - julearn - INFO -      svm__C: [0.01, 0.1, 1, 10]
2024-04-29 09:55:34,396 - julearn - INFO -      svm__gamma: [0.001, 0.01, 0.1, &#39;scale&#39;, &#39;auto&#39;]
2024-04-29 09:55:34,396 - julearn - INFO - Using inner CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:34,397 - julearn - INFO - Search Parameters:
2024-04-29 09:55:34,397 - julearn - INFO -      n_iter: 10
2024-04-29 09:55:34,397 - julearn - INFO -      cv: KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:34,397 - julearn - INFO - ====================
2024-04-29 09:55:34,397 - julearn - INFO -
2024-04-29 09:55:34,397 - julearn - INFO - = Data Information =
2024-04-29 09:55:34,397 - julearn - INFO -      Problem type: classification
2024-04-29 09:55:34,397 - julearn - INFO -      Number of samples: 100
2024-04-29 09:55:34,397 - julearn - INFO -      Number of features: 4
2024-04-29 09:55:34,397 - julearn - INFO - ====================
2024-04-29 09:55:34,397 - julearn - INFO -
2024-04-29 09:55:34,397 - julearn - INFO -      Number of classes: 2
2024-04-29 09:55:34,397 - julearn - INFO -      Target type: object
2024-04-29 09:55:34,398 - julearn - INFO -      Class distributions: species
versicolor    50
virginica     50
Name: count, dtype: int64
2024-04-29 09:55:34,398 - julearn - INFO - Using outer CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:34,398 - julearn - INFO - Binary classification problem detected.
/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(
2024-04-29 09:55:37,103 - julearn - INFO - Fitting final model
Scores with best hyperparameter using 10 iterations of randomized search: 0.89
{&#39;select_k__k&#39;: 3, &#39;svm__C&#39;: 1, &#39;svm__gamma&#39;: &#39;auto&#39;}
</pre></div>
</div>
<p>We can now see that the best hyperparameter might be different from the grid
search. This is because it tried only 10 combinations and not the whole grid.
Furthermore, the  <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code></a>
searcher can sample hyperparameters from distributions, which can be useful
when we have continuous hyperparameters.
Let’s set both <code class="docutils literal notranslate"><span class="pre">C</span></code> and <code class="docutils literal notranslate"><span class="pre">gamma</span></code> to be sampled from log-uniform
distributions. We can do this by setting the hyperparameter values as a
tuple with the following format: <code class="docutils literal notranslate"><span class="pre">(low,</span> <span class="pre">high,</span> <span class="pre">distribution)</span></code>. The
distribution can be either <code class="docutils literal notranslate"><span class="pre">&quot;log-uniform&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;uniform&quot;</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">creator</span> <span class="o">=</span> <span class="n">PipelineCreator</span><span class="p">(</span><span class="n">problem_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;zscore&quot;</span><span class="p">)</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;select_k&quot;</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="s2">&quot;svm&quot;</span><span class="p">,</span>
    <span class="n">C</span><span class="o">=</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="s2">&quot;log-uniform&quot;</span><span class="p">),</span>
    <span class="n">gamma</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="s2">&quot;log-uniform&quot;</span><span class="p">),</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">creator</span><span class="p">)</span>

<span class="n">scores_tuned</span><span class="p">,</span> <span class="n">model_tuned</span> <span class="o">=</span> <span class="n">run_cross_validation</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">X_types</span><span class="o">=</span><span class="n">X_types</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">creator</span><span class="p">,</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
    <span class="n">search_params</span><span class="o">=</span><span class="n">search_params</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Scores with best hyperparameter using 10 iterations of &quot;</span>
    <span class="sa">f</span><span class="s2">&quot;randomized search: </span><span class="si">{</span><span class="n">scores_tuned</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">model_tuned</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>2024-04-29 09:55:37,647 - julearn - INFO - Adding step zscore that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:37,647 - julearn - INFO - Step added
2024-04-29 09:55:37,647 - julearn - INFO - Adding step select_k that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:37,647 - julearn - INFO - Tuning hyperparameter k = [2, 3, 4]
2024-04-29 09:55:37,647 - julearn - INFO - Step added
2024-04-29 09:55:37,647 - julearn - INFO - Adding step svm that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:37,647 - julearn - INFO - Tuning hyperparameter C = (0.01, 10, &#39;log-uniform&#39;)
2024-04-29 09:55:37,647 - julearn - INFO - Tuning hyperparameter gamma = (0.001, 0.1, &#39;log-uniform&#39;)
2024-04-29 09:55:37,647 - julearn - INFO - Step added
PipelineCreator:
  Step 0: zscore
    estimator:     StandardScaler()
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {}
  Step 1: select_k
    estimator:     SelectKBest()
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {&#39;select_k__k&#39;: [2, 3, 4]}
  Step 2: svm
    estimator:     SVC()
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {&#39;svm__C&#39;: (0.01, 10, &#39;log-uniform&#39;), &#39;svm__gamma&#39;: (0.001, 0.1, &#39;log-uniform&#39;)}

2024-04-29 09:55:37,648 - julearn - INFO - ==== Input Data ====
2024-04-29 09:55:37,648 - julearn - INFO - Using dataframe as input
2024-04-29 09:55:37,648 - julearn - INFO -      Features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:37,648 - julearn - INFO -      Target: species
2024-04-29 09:55:37,648 - julearn - INFO -      Expanded features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:37,648 - julearn - INFO -      X_types:{&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]}
2024-04-29 09:55:37,649 - julearn - INFO - ====================
2024-04-29 09:55:37,649 - julearn - INFO -
2024-04-29 09:55:37,650 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:37,650 - julearn - INFO - Tuning hyperparameters using random
2024-04-29 09:55:37,650 - julearn - INFO - Hyperparameters:
2024-04-29 09:55:37,650 - julearn - INFO -      select_k__k: [2, 3, 4]
2024-04-29 09:55:37,650 - julearn - INFO -      svm__C: (0.01, 10, &#39;log-uniform&#39;)
2024-04-29 09:55:37,650 - julearn - INFO -      svm__gamma: (0.001, 0.1, &#39;log-uniform&#39;)
2024-04-29 09:55:37,651 - julearn - INFO - Using inner CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:37,651 - julearn - INFO - Search Parameters:
2024-04-29 09:55:37,651 - julearn - INFO -      n_iter: 10
2024-04-29 09:55:37,651 - julearn - INFO -      cv: KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:37,651 - julearn - INFO - ====================
2024-04-29 09:55:37,651 - julearn - INFO -
2024-04-29 09:55:37,651 - julearn - INFO - = Data Information =
2024-04-29 09:55:37,652 - julearn - INFO -      Problem type: classification
2024-04-29 09:55:37,652 - julearn - INFO -      Number of samples: 100
2024-04-29 09:55:37,652 - julearn - INFO -      Number of features: 4
2024-04-29 09:55:37,652 - julearn - INFO - ====================
2024-04-29 09:55:37,652 - julearn - INFO -
2024-04-29 09:55:37,652 - julearn - INFO -      Number of classes: 2
2024-04-29 09:55:37,652 - julearn - INFO -      Target type: object
2024-04-29 09:55:37,652 - julearn - INFO -      Class distributions: species
versicolor    50
virginica     50
Name: count, dtype: int64
2024-04-29 09:55:37,653 - julearn - INFO - Using outer CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:37,653 - julearn - INFO - Binary classification problem detected.
/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(
2024-04-29 09:55:40,389 - julearn - INFO - Fitting final model
Scores with best hyperparameter using 10 iterations of randomized search: 0.95
{&#39;select_k__k&#39;: 2,
 &#39;svm__C&#39;: 8.77140446796582,
 &#39;svm__gamma&#39;: 0.022636153281629743}
</pre></div>
</div>
<p>We can also control the number of cross-validation folds used by the searcher
by setting the <code class="docutils literal notranslate"><span class="pre">cv</span></code> parameter in the <code class="docutils literal notranslate"><span class="pre">search_params</span></code> dictionary. For
example, we can use a bayesian search with 3 folds. Fortunately, the
<a class="reference external" href="https://scikit-optimize.readthedocs.io/en/latest/modules/generated/skopt.BayesSearchCV.html#skopt.BayesSearchCV" title="(in scikit-optimize v0.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">BayesSearchCV</span></code></a> searcher also accepts distributions for the
hyperparameters.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">search_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;kind&quot;</span><span class="p">:</span> <span class="s2">&quot;bayes&quot;</span><span class="p">,</span>
    <span class="s2">&quot;n_iter&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s2">&quot;cv&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">scores_tuned</span><span class="p">,</span> <span class="n">model_tuned</span> <span class="o">=</span> <span class="n">run_cross_validation</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">X_types</span><span class="o">=</span><span class="n">X_types</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">creator</span><span class="p">,</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
    <span class="n">search_params</span><span class="o">=</span><span class="n">search_params</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Scores with best hyperparameter using 10 iterations of &quot;</span>
    <span class="sa">f</span><span class="s2">&quot;bayesian search and 3-fold CV: </span><span class="si">{</span><span class="n">scores_tuned</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">model_tuned</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>2024-04-29 09:55:40,941 - julearn - INFO - ==== Input Data ====
2024-04-29 09:55:40,942 - julearn - INFO - Using dataframe as input
2024-04-29 09:55:40,942 - julearn - INFO -      Features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:40,942 - julearn - INFO -      Target: species
2024-04-29 09:55:40,942 - julearn - INFO -      Expanded features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:40,942 - julearn - INFO -      X_types:{&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]}
2024-04-29 09:55:40,942 - julearn - INFO - ====================
2024-04-29 09:55:40,943 - julearn - INFO -
2024-04-29 09:55:40,943 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:40,943 - julearn - INFO - Tuning hyperparameters using bayes
2024-04-29 09:55:40,943 - julearn - INFO - Hyperparameters:
2024-04-29 09:55:40,943 - julearn - INFO -      select_k__k: [2, 3, 4]
2024-04-29 09:55:40,943 - julearn - INFO -      svm__C: (0.01, 10, &#39;log-uniform&#39;)
2024-04-29 09:55:40,943 - julearn - INFO -      svm__gamma: (0.001, 0.1, &#39;log-uniform&#39;)
2024-04-29 09:55:40,944 - julearn - INFO - Using inner CV scheme KFold(n_splits=3, random_state=None, shuffle=False)
2024-04-29 09:55:40,944 - julearn - INFO - Search Parameters:
2024-04-29 09:55:40,944 - julearn - INFO -      n_iter: 10
2024-04-29 09:55:40,944 - julearn - INFO -      cv: KFold(n_splits=3, random_state=None, shuffle=False)
2024-04-29 09:55:40,948 - julearn - INFO - ====================
2024-04-29 09:55:40,948 - julearn - INFO -
2024-04-29 09:55:40,948 - julearn - INFO - = Data Information =
2024-04-29 09:55:40,948 - julearn - INFO -      Problem type: classification
2024-04-29 09:55:40,948 - julearn - INFO -      Number of samples: 100
2024-04-29 09:55:40,948 - julearn - INFO -      Number of features: 4
2024-04-29 09:55:40,948 - julearn - INFO - ====================
2024-04-29 09:55:40,948 - julearn - INFO -
2024-04-29 09:55:40,948 - julearn - INFO -      Number of classes: 2
2024-04-29 09:55:40,948 - julearn - INFO -      Target type: object
2024-04-29 09:55:40,949 - julearn - INFO -      Class distributions: species
versicolor    50
virginica     50
Name: count, dtype: int64
2024-04-29 09:55:40,949 - julearn - INFO - Using outer CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:40,949 - julearn - INFO - Binary classification problem detected.
/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(
2024-04-29 09:55:45,790 - julearn - INFO - Fitting final model
Scores with best hyperparameter using 10 iterations of bayesian search and 3-fold CV: 0.9099999999999999
OrderedDict([(&#39;select_k__k&#39;, 4),
             (&#39;svm__C&#39;, 3.8975984906619887),
             (&#39;svm__gamma&#39;, 0.028707916525659204)])
</pre></div>
</div>
</section>
<section id="tuning-more-than-one-grid">
<h2>Tuning more than one <em>grid</em><a class="headerlink" href="#tuning-more-than-one-grid" title="Link to this heading">#</a></h2>
<p>Following our tuning of the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a> hyperparameters, we
can also see that we can tune the <code class="docutils literal notranslate"><span class="pre">kernel</span></code> hyperparameter. This
hyperparameter can also be “linear”. Let’s see how our <em>grid</em> of
hyperparameters would look like if we add this hyperparameter:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">creator</span> <span class="o">=</span> <span class="n">PipelineCreator</span><span class="p">(</span><span class="n">problem_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;zscore&quot;</span><span class="p">)</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="s2">&quot;svm&quot;</span><span class="p">,</span>
    <span class="n">C</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="n">gamma</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">],</span>
    <span class="n">kernel</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="s2">&quot;rbf&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">creator</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>2024-04-29 09:55:46,806 - julearn - INFO - Adding step zscore that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:46,806 - julearn - INFO - Step added
2024-04-29 09:55:46,806 - julearn - INFO - Adding step svm that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:46,807 - julearn - INFO - Tuning hyperparameter C = [0.01, 0.1, 1, 10]
2024-04-29 09:55:46,807 - julearn - INFO - Tuning hyperparameter gamma = [0.001, 0.01, &#39;scale&#39;, &#39;auto&#39;]
2024-04-29 09:55:46,807 - julearn - INFO - Tuning hyperparameter kernel = [&#39;linear&#39;, &#39;rbf&#39;]
2024-04-29 09:55:46,807 - julearn - INFO - Step added
PipelineCreator:
  Step 0: zscore
    estimator:     StandardScaler()
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {}
  Step 1: svm
    estimator:     SVC()
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {&#39;svm__C&#39;: [0.01, 0.1, 1, 10], &#39;svm__gamma&#39;: [0.001, 0.01, &#39;scale&#39;, &#39;auto&#39;], &#39;svm__kernel&#39;: [&#39;linear&#39;, &#39;rbf&#39;]}
</pre></div>
</div>
<p>We can see that the <em>grid</em> of hyperparameters is now 3-dimensional. However,
there are some combinations that don’t make much sense. For example, the
<code class="docutils literal notranslate"><span class="pre">gamma</span></code> hyperparameter is only used when the <code class="docutils literal notranslate"><span class="pre">kernel</span></code> is <code class="docutils literal notranslate"><span class="pre">rbf</span></code>. So
we will be trying the <code class="docutils literal notranslate"><span class="pre">linear</span></code> kernel with each one of the 4 different
<code class="docutils literal notranslate"><span class="pre">gamma</span></code> and 4 different <code class="docutils literal notranslate"><span class="pre">C</span></code> values. Those are 16 unnecessary combinations.
We can avoid this by using multiple <em>grids</em>. One grid for the <code class="docutils literal notranslate"><span class="pre">linear</span></code>
kernel and one grid for the <code class="docutils literal notranslate"><span class="pre">rbf</span></code> kernel.</p>
<p><code class="docutils literal notranslate"><span class="pre">julearn</span></code> allows to specify multiple <em>grid</em> using two different approaches.</p>
<ol class="arabic simple">
<li><p>Repeating the step name with different hyperparameters:</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">creator</span> <span class="o">=</span> <span class="n">PipelineCreator</span><span class="p">(</span><span class="n">problem_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;zscore&quot;</span><span class="p">)</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="s2">&quot;svm&quot;</span><span class="p">,</span>
    <span class="n">C</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="n">gamma</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">],</span>
    <span class="n">kernel</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;rbf&quot;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;svm&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">creator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="s2">&quot;svm&quot;</span><span class="p">,</span>
    <span class="n">C</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="n">kernel</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;linear&quot;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;svm&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">creator</span><span class="p">)</span>

<span class="n">scores1</span><span class="p">,</span> <span class="n">model1</span> <span class="o">=</span> <span class="n">run_cross_validation</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">X_types</span><span class="o">=</span><span class="n">X_types</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">creator</span><span class="p">,</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Scores with best hyperparameter: </span><span class="si">{</span><span class="n">scores1</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">model1</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>2024-04-29 09:55:46,809 - julearn - INFO - Adding step zscore that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:46,809 - julearn - INFO - Step added
2024-04-29 09:55:46,809 - julearn - INFO - Adding step svm that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:46,809 - julearn - INFO - Tuning hyperparameter C = [0.01, 0.1, 1, 10]
2024-04-29 09:55:46,809 - julearn - INFO - Tuning hyperparameter gamma = [0.001, 0.01, &#39;scale&#39;, &#39;auto&#39;]
2024-04-29 09:55:46,809 - julearn - INFO - Setting hyperparameter kernel = rbf
2024-04-29 09:55:46,809 - julearn - INFO - Step added
2024-04-29 09:55:46,809 - julearn - INFO - Adding step svm that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:46,809 - julearn - INFO - Tuning hyperparameter C = [0.01, 0.1, 1, 10]
2024-04-29 09:55:46,809 - julearn - INFO - Setting hyperparameter kernel = linear
2024-04-29 09:55:46,809 - julearn - INFO - Step added
PipelineCreator:
  Step 0: zscore
    estimator:     StandardScaler()
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {}
  Step 1: svm
    estimator:     SVC()
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {&#39;svm__C&#39;: [0.01, 0.1, 1, 10], &#39;svm__gamma&#39;: [0.001, 0.01, &#39;scale&#39;, &#39;auto&#39;]}
  Step 2: svm
    estimator:     SVC(kernel=&#39;linear&#39;)
    apply to:      ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    needed types:  ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
    tuning params: {&#39;svm__C&#39;: [0.01, 0.1, 1, 10]}

2024-04-29 09:55:46,811 - julearn - INFO - ==== Input Data ====
2024-04-29 09:55:46,811 - julearn - INFO - Using dataframe as input
2024-04-29 09:55:46,811 - julearn - INFO -      Features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:46,811 - julearn - INFO -      Target: species
2024-04-29 09:55:46,811 - julearn - INFO -      Expanded features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:46,811 - julearn - INFO -      X_types:{&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]}
2024-04-29 09:55:46,812 - julearn - INFO - ====================
2024-04-29 09:55:46,812 - julearn - INFO -
2024-04-29 09:55:46,813 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:46,813 - julearn - INFO - Tuning hyperparameters using grid
2024-04-29 09:55:46,813 - julearn - INFO - Hyperparameters:
2024-04-29 09:55:46,813 - julearn - INFO -      svm__C: [0.01, 0.1, 1, 10]
2024-04-29 09:55:46,813 - julearn - INFO -      svm__gamma: [0.001, 0.01, &#39;scale&#39;, &#39;auto&#39;]
2024-04-29 09:55:46,813 - julearn - INFO - Using inner CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:46,813 - julearn - INFO - Search Parameters:
2024-04-29 09:55:46,813 - julearn - INFO -      cv: KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:46,814 - julearn - INFO - ====================
2024-04-29 09:55:46,814 - julearn - INFO -
2024-04-29 09:55:46,814 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:46,814 - julearn - INFO - Tuning hyperparameters using grid
2024-04-29 09:55:46,814 - julearn - INFO - Hyperparameters:
2024-04-29 09:55:46,814 - julearn - INFO -      svm__C: [0.01, 0.1, 1, 10]
2024-04-29 09:55:46,815 - julearn - INFO - Using inner CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:46,815 - julearn - INFO - Search Parameters:
2024-04-29 09:55:46,815 - julearn - INFO -      cv: KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:46,815 - julearn - INFO - ====================
2024-04-29 09:55:46,815 - julearn - INFO -
2024-04-29 09:55:46,815 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:46,815 - julearn - INFO - Tuning hyperparameters using grid
2024-04-29 09:55:46,815 - julearn - INFO - Hyperparameters list:
2024-04-29 09:55:46,815 - julearn - INFO -      Set 0
2024-04-29 09:55:46,815 - julearn - INFO -              svm__C: [0.01, 0.1, 1, 10]
2024-04-29 09:55:46,815 - julearn - INFO -              svm__gamma: [0.001, 0.01, &#39;scale&#39;, &#39;auto&#39;]
2024-04-29 09:55:46,816 - julearn - INFO -              set_column_types: [SetColumnTypes(X_types={&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;,
                                       &#39;petal_length&#39;, &#39;petal_width&#39;]})]
2024-04-29 09:55:46,816 - julearn - INFO -              svm: [SVC()]
2024-04-29 09:55:46,816 - julearn - INFO -      Set 1
2024-04-29 09:55:46,816 - julearn - INFO -              svm__C: [0.01, 0.1, 1, 10]
2024-04-29 09:55:46,816 - julearn - INFO -              set_column_types: [SetColumnTypes(X_types={&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;,
                                       &#39;petal_length&#39;, &#39;petal_width&#39;]})]
2024-04-29 09:55:46,816 - julearn - INFO -              svm: [SVC(kernel=&#39;linear&#39;)]
2024-04-29 09:55:46,817 - julearn - INFO - Using inner CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:46,817 - julearn - INFO - Search Parameters:
2024-04-29 09:55:46,817 - julearn - INFO -      cv: KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:46,817 - julearn - INFO - ====================
2024-04-29 09:55:46,817 - julearn - INFO -
2024-04-29 09:55:46,817 - julearn - INFO - = Data Information =
2024-04-29 09:55:46,817 - julearn - INFO -      Problem type: classification
2024-04-29 09:55:46,817 - julearn - INFO -      Number of samples: 100
2024-04-29 09:55:46,817 - julearn - INFO -      Number of features: 4
2024-04-29 09:55:46,817 - julearn - INFO - ====================
2024-04-29 09:55:46,817 - julearn - INFO -
2024-04-29 09:55:46,817 - julearn - INFO -      Number of classes: 2
2024-04-29 09:55:46,817 - julearn - INFO -      Target type: object
2024-04-29 09:55:46,818 - julearn - INFO -      Class distributions: species
versicolor    50
virginica     50
Name: count, dtype: int64
2024-04-29 09:55:46,818 - julearn - INFO - Using outer CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:46,819 - julearn - INFO - Binary classification problem detected.
/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(
2024-04-29 09:55:51,138 - julearn - INFO - Fitting final model
Scores with best hyperparameter: 0.93
{&#39;set_column_types&#39;: SetColumnTypes(X_types={&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;,
                                       &#39;petal_length&#39;, &#39;petal_width&#39;]}),
 &#39;svm&#39;: SVC(),
 &#39;svm__C&#39;: 10,
 &#39;svm__gamma&#39;: 0.01}
</pre></div>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">name</span></code> parameter is required when repeating a step name.
If we do not specify the <code class="docutils literal notranslate"><span class="pre">name</span></code> parameter, <code class="docutils literal notranslate"><span class="pre">julearn</span></code> will
auto-determine the step name in an unique way. The only way to force repated
names is to do so explicitly.</p>
</div>
<ol class="arabic simple" start="2">
<li><p>Using multiple pipeline creators:</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">creator1</span> <span class="o">=</span> <span class="n">PipelineCreator</span><span class="p">(</span><span class="n">problem_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">creator1</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;zscore&quot;</span><span class="p">)</span>
<span class="n">creator1</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="s2">&quot;svm&quot;</span><span class="p">,</span>
    <span class="n">C</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="n">gamma</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">],</span>
    <span class="n">kernel</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;rbf&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">creator2</span> <span class="o">=</span> <span class="n">PipelineCreator</span><span class="p">(</span><span class="n">problem_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">creator2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;zscore&quot;</span><span class="p">)</span>
<span class="n">creator2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="s2">&quot;svm&quot;</span><span class="p">,</span>
    <span class="n">C</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="n">kernel</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;linear&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">scores2</span><span class="p">,</span> <span class="n">model2</span> <span class="o">=</span> <span class="n">run_cross_validation</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">X_types</span><span class="o">=</span><span class="n">X_types</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="p">[</span><span class="n">creator1</span><span class="p">,</span> <span class="n">creator2</span><span class="p">],</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
<span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Scores with best hyperparameter: </span><span class="si">{</span><span class="n">scores2</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">model2</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>2024-04-29 09:55:52,028 - julearn - INFO - Adding step zscore that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:52,028 - julearn - INFO - Step added
2024-04-29 09:55:52,028 - julearn - INFO - Adding step svm that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:52,029 - julearn - INFO - Tuning hyperparameter C = [0.01, 0.1, 1, 10]
2024-04-29 09:55:52,029 - julearn - INFO - Tuning hyperparameter gamma = [0.001, 0.01, &#39;scale&#39;, &#39;auto&#39;]
2024-04-29 09:55:52,029 - julearn - INFO - Setting hyperparameter kernel = rbf
2024-04-29 09:55:52,029 - julearn - INFO - Step added
2024-04-29 09:55:52,029 - julearn - INFO - Adding step zscore that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:52,029 - julearn - INFO - Step added
2024-04-29 09:55:52,029 - julearn - INFO - Adding step svm that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:52,029 - julearn - INFO - Tuning hyperparameter C = [0.01, 0.1, 1, 10]
2024-04-29 09:55:52,029 - julearn - INFO - Setting hyperparameter kernel = linear
2024-04-29 09:55:52,029 - julearn - INFO - Step added
2024-04-29 09:55:52,029 - julearn - INFO - ==== Input Data ====
2024-04-29 09:55:52,029 - julearn - INFO - Using dataframe as input
2024-04-29 09:55:52,029 - julearn - INFO -      Features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:52,029 - julearn - INFO -      Target: species
2024-04-29 09:55:52,030 - julearn - INFO -      Expanded features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:52,030 - julearn - INFO -      X_types:{&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]}
2024-04-29 09:55:52,030 - julearn - INFO - ====================
2024-04-29 09:55:52,030 - julearn - INFO -
2024-04-29 09:55:52,031 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:52,031 - julearn - INFO - Tuning hyperparameters using grid
2024-04-29 09:55:52,031 - julearn - INFO - Hyperparameters:
2024-04-29 09:55:52,031 - julearn - INFO -      svm__C: [0.01, 0.1, 1, 10]
2024-04-29 09:55:52,031 - julearn - INFO -      svm__gamma: [0.001, 0.01, &#39;scale&#39;, &#39;auto&#39;]
2024-04-29 09:55:52,031 - julearn - INFO - Using inner CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:52,031 - julearn - INFO - Search Parameters:
2024-04-29 09:55:52,032 - julearn - INFO -      cv: KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:52,032 - julearn - INFO - ====================
2024-04-29 09:55:52,032 - julearn - INFO -
2024-04-29 09:55:52,032 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:52,032 - julearn - INFO - Tuning hyperparameters using grid
2024-04-29 09:55:52,032 - julearn - INFO - Hyperparameters:
2024-04-29 09:55:52,032 - julearn - INFO -      svm__C: [0.01, 0.1, 1, 10]
2024-04-29 09:55:52,032 - julearn - INFO - Using inner CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:52,032 - julearn - INFO - Search Parameters:
2024-04-29 09:55:52,033 - julearn - INFO -      cv: KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:52,033 - julearn - INFO - ====================
2024-04-29 09:55:52,033 - julearn - INFO -
2024-04-29 09:55:52,033 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:52,033 - julearn - INFO - Tuning hyperparameters using grid
2024-04-29 09:55:52,033 - julearn - INFO - Hyperparameters list:
2024-04-29 09:55:52,033 - julearn - INFO -      Set 0
2024-04-29 09:55:52,033 - julearn - INFO -              svm__C: [0.01, 0.1, 1, 10]
2024-04-29 09:55:52,033 - julearn - INFO -              svm__gamma: [0.001, 0.01, &#39;scale&#39;, &#39;auto&#39;]
2024-04-29 09:55:52,033 - julearn - INFO -              set_column_types: [SetColumnTypes(X_types={&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;,
                                       &#39;petal_length&#39;, &#39;petal_width&#39;]})]
2024-04-29 09:55:52,033 - julearn - INFO -              zscore: [StandardScaler()]
2024-04-29 09:55:52,034 - julearn - INFO -              svm: [SVC()]
2024-04-29 09:55:52,034 - julearn - INFO -      Set 1
2024-04-29 09:55:52,034 - julearn - INFO -              svm__C: [0.01, 0.1, 1, 10]
2024-04-29 09:55:52,034 - julearn - INFO -              set_column_types: [SetColumnTypes(X_types={&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;,
                                       &#39;petal_length&#39;, &#39;petal_width&#39;]})]
2024-04-29 09:55:52,034 - julearn - INFO -              zscore: [StandardScaler()]
2024-04-29 09:55:52,034 - julearn - INFO -              svm: [SVC(kernel=&#39;linear&#39;)]
2024-04-29 09:55:52,035 - julearn - INFO - Using inner CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:52,035 - julearn - INFO - Search Parameters:
2024-04-29 09:55:52,035 - julearn - INFO -      cv: KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:52,035 - julearn - INFO - ====================
2024-04-29 09:55:52,035 - julearn - INFO -
2024-04-29 09:55:52,035 - julearn - INFO - = Data Information =
2024-04-29 09:55:52,035 - julearn - INFO -      Problem type: classification
2024-04-29 09:55:52,035 - julearn - INFO -      Number of samples: 100
2024-04-29 09:55:52,035 - julearn - INFO -      Number of features: 4
2024-04-29 09:55:52,035 - julearn - INFO - ====================
2024-04-29 09:55:52,035 - julearn - INFO -
2024-04-29 09:55:52,035 - julearn - INFO -      Number of classes: 2
2024-04-29 09:55:52,035 - julearn - INFO -      Target type: object
2024-04-29 09:55:52,036 - julearn - INFO -      Class distributions: species
versicolor    50
virginica     50
Name: count, dtype: int64
2024-04-29 09:55:52,036 - julearn - INFO - Using outer CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:52,036 - julearn - INFO - Binary classification problem detected.
/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(
2024-04-29 09:55:56,389 - julearn - INFO - Fitting final model
Scores with best hyperparameter: 0.93
{&#39;set_column_types&#39;: SetColumnTypes(X_types={&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;,
                                       &#39;petal_length&#39;, &#39;petal_width&#39;]}),
 &#39;svm&#39;: SVC(),
 &#39;svm__C&#39;: 10,
 &#39;svm__gamma&#39;: 0.01,
 &#39;zscore&#39;: StandardScaler()}
</pre></div>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>All the pipeline creators must have the same problem type and steps names
in order for this approach to work.</p>
</div>
<p>Indeed, if we compare both approaches, we can see that they are equivalent.
They both produce the same <em>grid</em> of hyperparameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pprint</span><span class="p">(</span><span class="n">model1</span><span class="o">.</span><span class="n">param_grid</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">model2</span><span class="o">.</span><span class="n">param_grid</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[{&#39;set_column_types&#39;: [SetColumnTypes(X_types={&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;,
                                       &#39;petal_length&#39;, &#39;petal_width&#39;]})],
  &#39;svm&#39;: [SVC()],
  &#39;svm__C&#39;: [0.01, 0.1, 1, 10],
  &#39;svm__gamma&#39;: [0.001, 0.01, &#39;scale&#39;, &#39;auto&#39;]},
 {&#39;set_column_types&#39;: [SetColumnTypes(X_types={&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;,
                                       &#39;petal_length&#39;, &#39;petal_width&#39;]})],
  &#39;svm&#39;: [SVC(kernel=&#39;linear&#39;)],
  &#39;svm__C&#39;: [0.01, 0.1, 1, 10]}]
[{&#39;set_column_types&#39;: [SetColumnTypes(X_types={&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;,
                                       &#39;petal_length&#39;, &#39;petal_width&#39;]})],
  &#39;svm&#39;: [SVC()],
  &#39;svm__C&#39;: [0.01, 0.1, 1, 10],
  &#39;svm__gamma&#39;: [0.001, 0.01, &#39;scale&#39;, &#39;auto&#39;],
  &#39;zscore&#39;: [StandardScaler()]},
 {&#39;set_column_types&#39;: [SetColumnTypes(X_types={&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;,
                                       &#39;petal_length&#39;, &#39;petal_width&#39;]})],
  &#39;svm&#39;: [SVC(kernel=&#39;linear&#39;)],
  &#39;svm__C&#39;: [0.01, 0.1, 1, 10],
  &#39;zscore&#39;: [StandardScaler()]}]
</pre></div>
</div>
</section>
<section id="models-as-hyperparameters">
<h2>Models as hyperparameters<a class="headerlink" href="#models-as-hyperparameters" title="Link to this heading">#</a></h2>
<p>But why stop there? Models can also be considered as hyperparameters. For
example, we can try different models for the classification task. Let’s
try the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code></a> and the
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticRegression</span></code></a> too:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">creator1</span> <span class="o">=</span> <span class="n">PipelineCreator</span><span class="p">(</span><span class="n">problem_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">creator1</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;zscore&quot;</span><span class="p">)</span>
<span class="n">creator1</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="s2">&quot;svm&quot;</span><span class="p">,</span>
    <span class="n">C</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="n">gamma</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">],</span>
    <span class="n">kernel</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;rbf&quot;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">creator2</span> <span class="o">=</span> <span class="n">PipelineCreator</span><span class="p">(</span><span class="n">problem_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">creator2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;zscore&quot;</span><span class="p">)</span>
<span class="n">creator2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="s2">&quot;svm&quot;</span><span class="p">,</span>
    <span class="n">C</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="n">kernel</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;linear&quot;</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">creator3</span> <span class="o">=</span> <span class="n">PipelineCreator</span><span class="p">(</span><span class="n">problem_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">creator3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;zscore&quot;</span><span class="p">)</span>
<span class="n">creator3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="s2">&quot;rf&quot;</span><span class="p">,</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">creator4</span> <span class="o">=</span> <span class="n">PipelineCreator</span><span class="p">(</span><span class="n">problem_type</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">creator4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;zscore&quot;</span><span class="p">)</span>
<span class="n">creator4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="s2">&quot;logit&quot;</span><span class="p">,</span>
    <span class="n">penalty</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;l2&quot;</span><span class="p">,</span> <span class="s2">&quot;l1&quot;</span><span class="p">],</span>
    <span class="n">dual</span><span class="o">=</span><span class="p">[</span><span class="kc">False</span><span class="p">],</span>
    <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">scores3</span><span class="p">,</span> <span class="n">model3</span> <span class="o">=</span> <span class="n">run_cross_validation</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">X_types</span><span class="o">=</span><span class="n">X_types</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="p">[</span><span class="n">creator1</span><span class="p">,</span> <span class="n">creator2</span><span class="p">,</span> <span class="n">creator3</span><span class="p">,</span> <span class="n">creator4</span><span class="p">],</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
<span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Scores with best hyperparameter: </span><span class="si">{</span><span class="n">scores3</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">model3</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>2024-04-29 09:55:57,262 - julearn - INFO - Adding step zscore that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:57,262 - julearn - INFO - Step added
2024-04-29 09:55:57,262 - julearn - INFO - Adding step model that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:57,262 - julearn - INFO - Tuning hyperparameter C = [0.01, 0.1, 1, 10]
2024-04-29 09:55:57,262 - julearn - INFO - Tuning hyperparameter gamma = [0.001, 0.01, &#39;scale&#39;, &#39;auto&#39;]
2024-04-29 09:55:57,262 - julearn - INFO - Setting hyperparameter kernel = rbf
2024-04-29 09:55:57,262 - julearn - INFO - Step added
2024-04-29 09:55:57,262 - julearn - INFO - Adding step zscore that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:57,262 - julearn - INFO - Step added
2024-04-29 09:55:57,262 - julearn - INFO - Adding step model that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:57,262 - julearn - INFO - Tuning hyperparameter C = [0.01, 0.1, 1, 10]
2024-04-29 09:55:57,262 - julearn - INFO - Setting hyperparameter kernel = linear
2024-04-29 09:55:57,263 - julearn - INFO - Step added
2024-04-29 09:55:57,263 - julearn - INFO - Adding step zscore that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:57,263 - julearn - INFO - Step added
2024-04-29 09:55:57,263 - julearn - INFO - Adding step model that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:57,263 - julearn - INFO - Tuning hyperparameter max_depth = [2, 3, 4]
2024-04-29 09:55:57,263 - julearn - INFO - Step added
2024-04-29 09:55:57,263 - julearn - INFO - Adding step zscore that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:57,263 - julearn - INFO - Step added
2024-04-29 09:55:57,263 - julearn - INFO - Adding step model that applies to ColumnTypes&lt;types={&#39;continuous&#39;}; pattern=(?:__:type:__continuous)&gt;
2024-04-29 09:55:57,263 - julearn - INFO - Tuning hyperparameter penalty = [&#39;l2&#39;, &#39;l1&#39;]
2024-04-29 09:55:57,263 - julearn - INFO - Setting hyperparameter dual = False
2024-04-29 09:55:57,263 - julearn - INFO - Setting hyperparameter solver = liblinear
2024-04-29 09:55:57,263 - julearn - INFO - Step added
2024-04-29 09:55:57,263 - julearn - INFO - ==== Input Data ====
2024-04-29 09:55:57,263 - julearn - INFO - Using dataframe as input
2024-04-29 09:55:57,264 - julearn - INFO -      Features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:57,264 - julearn - INFO -      Target: species
2024-04-29 09:55:57,264 - julearn - INFO -      Expanded features: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]
2024-04-29 09:55:57,264 - julearn - INFO -      X_types:{&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]}
2024-04-29 09:55:57,265 - julearn - INFO - ====================
2024-04-29 09:55:57,265 - julearn - INFO -
2024-04-29 09:55:57,265 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:57,265 - julearn - INFO - Tuning hyperparameters using grid
2024-04-29 09:55:57,265 - julearn - INFO - Hyperparameters:
2024-04-29 09:55:57,265 - julearn - INFO -      model__C: [0.01, 0.1, 1, 10]
2024-04-29 09:55:57,265 - julearn - INFO -      model__gamma: [0.001, 0.01, &#39;scale&#39;, &#39;auto&#39;]
2024-04-29 09:55:57,266 - julearn - INFO - Using inner CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:57,266 - julearn - INFO - Search Parameters:
2024-04-29 09:55:57,266 - julearn - INFO -      cv: KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:57,266 - julearn - INFO - ====================
2024-04-29 09:55:57,266 - julearn - INFO -
2024-04-29 09:55:57,266 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:57,266 - julearn - INFO - Tuning hyperparameters using grid
2024-04-29 09:55:57,266 - julearn - INFO - Hyperparameters:
2024-04-29 09:55:57,266 - julearn - INFO -      model__C: [0.01, 0.1, 1, 10]
2024-04-29 09:55:57,267 - julearn - INFO - Using inner CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:57,267 - julearn - INFO - Search Parameters:
2024-04-29 09:55:57,267 - julearn - INFO -      cv: KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:57,267 - julearn - INFO - ====================
2024-04-29 09:55:57,267 - julearn - INFO -
2024-04-29 09:55:57,267 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:57,267 - julearn - INFO - Tuning hyperparameters using grid
2024-04-29 09:55:57,267 - julearn - INFO - Hyperparameters:
2024-04-29 09:55:57,267 - julearn - INFO -      model__max_depth: [2, 3, 4]
2024-04-29 09:55:57,268 - julearn - INFO - Using inner CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:57,268 - julearn - INFO - Search Parameters:
2024-04-29 09:55:57,268 - julearn - INFO -      cv: KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:57,268 - julearn - INFO - ====================
2024-04-29 09:55:57,268 - julearn - INFO -
2024-04-29 09:55:57,268 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:57,268 - julearn - INFO - Tuning hyperparameters using grid
2024-04-29 09:55:57,268 - julearn - INFO - Hyperparameters:
2024-04-29 09:55:57,268 - julearn - INFO -      model__penalty: [&#39;l2&#39;, &#39;l1&#39;]
2024-04-29 09:55:57,269 - julearn - INFO - Using inner CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:57,269 - julearn - INFO - Search Parameters:
2024-04-29 09:55:57,269 - julearn - INFO -      cv: KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:57,269 - julearn - INFO - ====================
2024-04-29 09:55:57,269 - julearn - INFO -
2024-04-29 09:55:57,269 - julearn - INFO - = Model Parameters =
2024-04-29 09:55:57,269 - julearn - INFO - Tuning hyperparameters using grid
2024-04-29 09:55:57,269 - julearn - INFO - Hyperparameters list:
2024-04-29 09:55:57,269 - julearn - INFO -      Set 0
2024-04-29 09:55:57,269 - julearn - INFO -              model__C: [0.01, 0.1, 1, 10]
2024-04-29 09:55:57,269 - julearn - INFO -              model__gamma: [0.001, 0.01, &#39;scale&#39;, &#39;auto&#39;]
2024-04-29 09:55:57,269 - julearn - INFO -              set_column_types: [SetColumnTypes(X_types={&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;,
                                       &#39;petal_length&#39;, &#39;petal_width&#39;]})]
2024-04-29 09:55:57,270 - julearn - INFO -              zscore: [StandardScaler()]
2024-04-29 09:55:57,270 - julearn - INFO -              model: [SVC()]
2024-04-29 09:55:57,270 - julearn - INFO -      Set 1
2024-04-29 09:55:57,270 - julearn - INFO -              model__C: [0.01, 0.1, 1, 10]
2024-04-29 09:55:57,270 - julearn - INFO -              set_column_types: [SetColumnTypes(X_types={&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;,
                                       &#39;petal_length&#39;, &#39;petal_width&#39;]})]
2024-04-29 09:55:57,270 - julearn - INFO -              zscore: [StandardScaler()]
2024-04-29 09:55:57,270 - julearn - INFO -              model: [SVC(kernel=&#39;linear&#39;)]
2024-04-29 09:55:57,271 - julearn - INFO -      Set 2
2024-04-29 09:55:57,271 - julearn - INFO -              model__max_depth: [2, 3, 4]
2024-04-29 09:55:57,271 - julearn - INFO -              set_column_types: [SetColumnTypes(X_types={&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;,
                                       &#39;petal_length&#39;, &#39;petal_width&#39;]})]
2024-04-29 09:55:57,271 - julearn - INFO -              zscore: [StandardScaler()]
2024-04-29 09:55:57,271 - julearn - INFO -              model: [RandomForestClassifier()]
2024-04-29 09:55:57,271 - julearn - INFO -      Set 3
2024-04-29 09:55:57,271 - julearn - INFO -              model__penalty: [&#39;l2&#39;, &#39;l1&#39;]
2024-04-29 09:55:57,271 - julearn - INFO -              set_column_types: [SetColumnTypes(X_types={&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;,
                                       &#39;petal_length&#39;, &#39;petal_width&#39;]})]
2024-04-29 09:55:57,272 - julearn - INFO -              zscore: [StandardScaler()]
2024-04-29 09:55:57,272 - julearn - INFO -              model: [LogisticRegression(solver=&#39;liblinear&#39;)]
2024-04-29 09:55:57,272 - julearn - INFO - Using inner CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:57,272 - julearn - INFO - Search Parameters:
2024-04-29 09:55:57,272 - julearn - INFO -      cv: KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:57,272 - julearn - INFO - ====================
2024-04-29 09:55:57,272 - julearn - INFO -
2024-04-29 09:55:57,272 - julearn - INFO - = Data Information =
2024-04-29 09:55:57,272 - julearn - INFO -      Problem type: classification
2024-04-29 09:55:57,272 - julearn - INFO -      Number of samples: 100
2024-04-29 09:55:57,272 - julearn - INFO -      Number of features: 4
2024-04-29 09:55:57,272 - julearn - INFO - ====================
2024-04-29 09:55:57,272 - julearn - INFO -
2024-04-29 09:55:57,273 - julearn - INFO -      Number of classes: 2
2024-04-29 09:55:57,273 - julearn - INFO -      Target type: object
2024-04-29 09:55:57,273 - julearn - INFO -      Class distributions: species
versicolor    50
virginica     50
Name: count, dtype: int64
2024-04-29 09:55:57,274 - julearn - INFO - Using outer CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
2024-04-29 09:55:57,274 - julearn - INFO - Binary classification problem detected.
/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
  warnings.warn(
2024-04-29 09:56:09,639 - julearn - INFO - Fitting final model
Scores with best hyperparameter: 0.9200000000000002
{&#39;model&#39;: SVC(),
 &#39;model__C&#39;: 10,
 &#39;model__gamma&#39;: 0.01,
 &#39;set_column_types&#39;: SetColumnTypes(X_types={&#39;continuous&#39;: [&#39;sepal_length&#39;, &#39;sepal_width&#39;,
                                       &#39;petal_length&#39;, &#39;petal_width&#39;]}),
 &#39;zscore&#39;: StandardScaler()}
</pre></div>
</div>
<p>Well, it seems that nothing can beat the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="(in scikit-learn v1.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a> with
<code class="docutils literal notranslate"><span class="pre">kernel=&quot;rbf&quot;</span></code> for our classification example.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (1 minutes 7.705 seconds)</p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="model_inspect.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title"><span class="section-number">6.4. </span>Inspecting Models</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="confound_removal.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title"><span class="section-number">6.2. </span>Cross-validation consistent Confound Removal</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, Authors of julearn
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">6.3. Hyperparameter Tuning</a><ul>
<li><a class="reference internal" href="#parameters-vs-hyperparameters">Parameters vs Hyperparameters</a></li>
<li><a class="reference internal" href="#id1">Hyperparameter Tuning</a></li>
<li><a class="reference internal" href="#searchers">Searchers</a></li>
<li><a class="reference internal" href="#tuning-more-than-one-grid">Tuning more than one <em>grid</em></a></li>
<li><a class="reference internal" href="#models-as-hyperparameters">Models as hyperparameters</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=32e29ea5"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/js/custom.js?v=9868c0c7"></script>
    </body>
</html>