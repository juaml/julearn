
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/04_confounds/run_return_confounds.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_04_confounds_run_return_confounds.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_04_confounds_run_return_confounds.py:


Return Confounds in Confound Removal
====================================

In most cases confound removal is a simple operation.
You regress out the confound from the features and only continue working with
these new confound removed features. This is also the default setting for
``julearn``'s ``remove_confound`` step. But sometimes you want to work with the
confound even after removing it from the features. In this example, we
will discuss the options you have.

.. include:: ../../links.inc

.. GENERATED FROM PYTHON SOURCE LINES 14-25

.. code-block:: default

    # Authors: Sami Hamdan <s.hamdan@fz-juelich.de>
    # License: AGPL

    from sklearn.datasets import load_diabetes  # to load data
    from julearn.pipeline import PipelineCreator
    from julearn import run_cross_validation
    from julearn.inspect import preprocess

    # Load in the data
    df_features, target = load_diabetes(return_X_y=True, as_frame=True)








.. GENERATED FROM PYTHON SOURCE LINES 26-30

First, we can have a look at our features.
You can see it includes Age, BMI, average blood pressure (bp) and 6 other
measures from s1 to s6. Furthermore, it includes sex which will be considered
as a confound in this example.

.. GENERATED FROM PYTHON SOURCE LINES 30-32

.. code-block:: default

    print("Features: ", df_features.head())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Features:          age       sex       bmi  ...        s4        s5        s6
    0  0.038076  0.050680  0.061696  ... -0.002592  0.019907 -0.017646
    1 -0.001882 -0.044642 -0.051474  ... -0.039493 -0.068332 -0.092204
    2  0.085299  0.050680  0.044451  ... -0.002592  0.002861 -0.025930
    3 -0.089063 -0.044642 -0.011595  ...  0.034309  0.022688 -0.009362
    4  0.005383 -0.044642 -0.036385  ... -0.002592 -0.031988 -0.046641

    [5 rows x 10 columns]




.. GENERATED FROM PYTHON SOURCE LINES 33-34

Second, we can have a look at the target.

.. GENERATED FROM PYTHON SOURCE LINES 34-36

.. code-block:: default

    print("Target: ", target.describe())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Target:  count    442.000000
    mean     152.133484
    std       77.093005
    min       25.000000
    25%       87.000000
    50%      140.500000
    75%      211.500000
    max      346.000000
    Name: target, dtype: float64




.. GENERATED FROM PYTHON SOURCE LINES 37-38

Now, we can put both into one DataFrame:

.. GENERATED FROM PYTHON SOURCE LINES 38-41

.. code-block:: default

    data = df_features.copy()
    data["target"] = target








.. GENERATED FROM PYTHON SOURCE LINES 42-51

In the following we will explore different settings of confound removal
using ``julearn``'s pipeline functionalities.

Confound Removal Typical Use Case
---------------------------------
Here, we want to deconfound the features and not include the confound as a
feature into our last model. We will use the ``remove_confound`` step for this.
Then we will use the ``pca`` step to reduce the dimensionality of the features.
Finally, we will fit a linear regression model.

.. GENERATED FROM PYTHON SOURCE LINES 51-57

.. code-block:: default


    creator = PipelineCreator(problem_type="regression", apply_to="continuous")
    creator.add("confound_removal")
    creator.add("pca")
    creator.add("linreg")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    2024-04-29 09:50:38,652 - julearn - INFO - Adding step confound_removal that applies to ColumnTypes<types={'continuous'}; pattern=(?:__:type:__continuous)>
    2024-04-29 09:50:38,652 - julearn - INFO - Step added
    2024-04-29 09:50:38,652 - julearn - INFO - Adding step pca that applies to ColumnTypes<types={'continuous'}; pattern=(?:__:type:__continuous)>
    2024-04-29 09:50:38,652 - julearn - INFO - Step added
    2024-04-29 09:50:38,653 - julearn - INFO - Adding step linreg that applies to ColumnTypes<types={'continuous'}; pattern=(?:__:type:__continuous)>
    2024-04-29 09:50:38,653 - julearn - INFO - Step added

    <julearn.pipeline.pipeline_creator.PipelineCreator object at 0x7f5450e16c20>



.. GENERATED FROM PYTHON SOURCE LINES 58-64

Now we need to set the ``X_types`` argument of the ``run_cross_validation``
function. This argument is a dictionary that maps the names of the different
types of X to the features that belong to this type. In this example, we
have two types of features: `continuous` and `confound`. The `continuous`
features are the features that we want to deconfound and the `confound`
features are the features that we want to remove from the `continuous`.

.. GENERATED FROM PYTHON SOURCE LINES 64-70

.. code-block:: default


    feature_names = list(df_features.drop(columns="sex").columns)
    X_types = {"continuous": feature_names, "confound": "sex"}

    X = feature_names + ["sex"]








.. GENERATED FROM PYTHON SOURCE LINES 71-72

Now we can run the cross validation and get the scores.

.. GENERATED FROM PYTHON SOURCE LINES 72-81

.. code-block:: default

    scores, model = run_cross_validation(
        X=X,
        y="target",
        X_types=X_types,
        data=data,
        model=creator,
        return_estimator="final",
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    2024-04-29 09:50:38,654 - julearn - INFO - ==== Input Data ====
    2024-04-29 09:50:38,654 - julearn - INFO - Using dataframe as input
    2024-04-29 09:50:38,654 - julearn - INFO -      Features: ['age', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'sex']
    2024-04-29 09:50:38,654 - julearn - INFO -      Target: target
    2024-04-29 09:50:38,654 - julearn - INFO -      Expanded features: ['age', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'sex']
    2024-04-29 09:50:38,654 - julearn - INFO -      X_types:{'continuous': ['age', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'], 'confound': ['sex']}
    2024-04-29 09:50:38,655 - julearn - INFO - ====================
    2024-04-29 09:50:38,655 - julearn - INFO - 
    2024-04-29 09:50:38,656 - julearn - INFO - = Model Parameters =
    2024-04-29 09:50:38,656 - julearn - INFO - ====================
    2024-04-29 09:50:38,656 - julearn - INFO - 
    2024-04-29 09:50:38,657 - julearn - INFO - = Data Information =
    2024-04-29 09:50:38,657 - julearn - INFO -      Problem type: regression
    2024-04-29 09:50:38,657 - julearn - INFO -      Number of samples: 442
    2024-04-29 09:50:38,657 - julearn - INFO -      Number of features: 10
    2024-04-29 09:50:38,657 - julearn - INFO - ====================
    2024-04-29 09:50:38,657 - julearn - INFO - 
    2024-04-29 09:50:38,657 - julearn - INFO -      Target type: float64
    2024-04-29 09:50:38,657 - julearn - INFO - Using outer CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
    /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
      warnings.warn(
    2024-04-29 09:50:38,837 - julearn - INFO - Fitting final model




.. GENERATED FROM PYTHON SOURCE LINES 82-87

We can use the ``preprocess`` method of the ``inspect`` module to inspect the
transformations steps of the returned estimator.
By providing a step name to the ``until`` argument of the
``preprocess`` method we return the transformed X and y up to
the provided step (inclusive).

.. GENERATED FROM PYTHON SOURCE LINES 87-90

.. code-block:: default

    df_deconfounded = preprocess(model, X=X, data=data, until="confound_removal")
    df_deconfounded.head()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>age</th>
          <th>bmi</th>
          <th>bp</th>
          <th>s1</th>
          <th>s2</th>
          <th>s3</th>
          <th>s4</th>
          <th>s5</th>
          <th>s6</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>0.029271</td>
          <td>0.057228</td>
          <td>0.009658</td>
          <td>-0.046011</td>
          <td>-0.042050</td>
          <td>-0.024189</td>
          <td>-0.019424</td>
          <td>0.012310</td>
          <td>-0.028194</td>
        </tr>
        <tr>
          <th>1</th>
          <td>0.005874</td>
          <td>-0.047538</td>
          <td>-0.015568</td>
          <td>-0.006874</td>
          <td>-0.012796</td>
          <td>0.057488</td>
          <td>-0.024667</td>
          <td>-0.061639</td>
          <td>-0.082913</td>
        </tr>
        <tr>
          <th>2</th>
          <td>0.076494</td>
          <td>0.039983</td>
          <td>-0.017885</td>
          <td>-0.047387</td>
          <td>-0.041423</td>
          <td>-0.013144</td>
          <td>-0.019424</td>
          <td>-0.004736</td>
          <td>-0.036479</td>
        </tr>
        <tr>
          <th>3</th>
          <td>-0.081307</td>
          <td>-0.007659</td>
          <td>-0.025897</td>
          <td>0.013765</td>
          <td>0.031358</td>
          <td>-0.052961</td>
          <td>0.049135</td>
          <td>0.029380</td>
          <td>-0.000071</td>
        </tr>
        <tr>
          <th>4</th>
          <td>0.013139</td>
          <td>-0.032449</td>
          <td>0.032631</td>
          <td>0.005510</td>
          <td>0.021964</td>
          <td>-0.008781</td>
          <td>0.012234</td>
          <td>-0.025295</td>
          <td>-0.037349</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 91-107

As you can see the confound ``sex`` was dropped and only the confound removed
features are used in the following PCA.

But what if you want to keep the confound after removal for
other transformations?

For example, let's assume that you want to do a PCA on the confound removed
feature, but want to keep the confound for the actual modelling step.
Let us have a closer look to the confound remover in order to understand
how we could achieve such a task:

.. autoclass:: julearn.transformers.confound_remover.ConfoundRemover
   :noindex:
   :exclude-members: transform, get_support, get_feature_names_out,
                     filter_columns, fit, fit_transform, get_apply_to,
                     get_needed_types, get_params, set_output, set_params

.. GENERATED FROM PYTHON SOURCE LINES 109-111

In this example, we will set the ``keep_confounds`` argument to True.
This will keep the confounds after confound removal.

.. GENERATED FROM PYTHON SOURCE LINES 111-117

.. code-block:: default


    creator = PipelineCreator(problem_type="regression", apply_to="continuous")
    creator.add("confound_removal", keep_confounds=True)
    creator.add("pca")
    creator.add("linreg")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    2024-04-29 09:50:38,875 - julearn - INFO - Adding step confound_removal that applies to ColumnTypes<types={'continuous'}; pattern=(?:__:type:__continuous)>
    2024-04-29 09:50:38,875 - julearn - INFO - Setting hyperparameter keep_confounds = True
    2024-04-29 09:50:38,875 - julearn - INFO - Step added
    2024-04-29 09:50:38,875 - julearn - INFO - Adding step pca that applies to ColumnTypes<types={'continuous'}; pattern=(?:__:type:__continuous)>
    2024-04-29 09:50:38,875 - julearn - INFO - Step added
    2024-04-29 09:50:38,875 - julearn - INFO - Adding step linreg that applies to ColumnTypes<types={'continuous'}; pattern=(?:__:type:__continuous)>
    2024-04-29 09:50:38,875 - julearn - INFO - Step added

    <julearn.pipeline.pipeline_creator.PipelineCreator object at 0x7f5450e17070>



.. GENERATED FROM PYTHON SOURCE LINES 118-119

Now we can run the cross validation and get the scores.

.. GENERATED FROM PYTHON SOURCE LINES 119-128

.. code-block:: default

    scores, model = run_cross_validation(
        X=X,
        y="target",
        X_types=X_types,
        data=data,
        model=creator,
        return_estimator="final",
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    2024-04-29 09:50:38,876 - julearn - INFO - ==== Input Data ====
    2024-04-29 09:50:38,876 - julearn - INFO - Using dataframe as input
    2024-04-29 09:50:38,876 - julearn - INFO -      Features: ['age', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'sex']
    2024-04-29 09:50:38,876 - julearn - INFO -      Target: target
    2024-04-29 09:50:38,876 - julearn - INFO -      Expanded features: ['age', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'sex']
    2024-04-29 09:50:38,876 - julearn - INFO -      X_types:{'continuous': ['age', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'], 'confound': ['sex']}
    2024-04-29 09:50:38,877 - julearn - INFO - ====================
    2024-04-29 09:50:38,877 - julearn - INFO - 
    2024-04-29 09:50:38,878 - julearn - INFO - = Model Parameters =
    2024-04-29 09:50:38,878 - julearn - INFO - ====================
    2024-04-29 09:50:38,878 - julearn - INFO - 
    2024-04-29 09:50:38,878 - julearn - INFO - = Data Information =
    2024-04-29 09:50:38,878 - julearn - INFO -      Problem type: regression
    2024-04-29 09:50:38,878 - julearn - INFO -      Number of samples: 442
    2024-04-29 09:50:38,878 - julearn - INFO -      Number of features: 10
    2024-04-29 09:50:38,878 - julearn - INFO - ====================
    2024-04-29 09:50:38,878 - julearn - INFO - 
    2024-04-29 09:50:38,878 - julearn - INFO -      Target type: float64
    2024-04-29 09:50:38,879 - julearn - INFO - Using outer CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
    /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
      warnings.warn(
    2024-04-29 09:50:39,058 - julearn - INFO - Fitting final model




.. GENERATED FROM PYTHON SOURCE LINES 129-130

As you can see this kept the confound variable ``sex`` in the data.

.. GENERATED FROM PYTHON SOURCE LINES 130-133

.. code-block:: default

    df_deconfounded = preprocess(model, X=X, data=data, until="confound_removal")
    df_deconfounded.head()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>age</th>
          <th>bmi</th>
          <th>bp</th>
          <th>s1</th>
          <th>s2</th>
          <th>s3</th>
          <th>s4</th>
          <th>s5</th>
          <th>s6</th>
          <th>sex</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>0.029271</td>
          <td>0.057228</td>
          <td>0.009658</td>
          <td>-0.046011</td>
          <td>-0.042050</td>
          <td>-0.024189</td>
          <td>-0.019424</td>
          <td>0.012310</td>
          <td>-0.028194</td>
          <td>0.050680</td>
        </tr>
        <tr>
          <th>1</th>
          <td>0.005874</td>
          <td>-0.047538</td>
          <td>-0.015568</td>
          <td>-0.006874</td>
          <td>-0.012796</td>
          <td>0.057488</td>
          <td>-0.024667</td>
          <td>-0.061639</td>
          <td>-0.082913</td>
          <td>-0.044642</td>
        </tr>
        <tr>
          <th>2</th>
          <td>0.076494</td>
          <td>0.039983</td>
          <td>-0.017885</td>
          <td>-0.047387</td>
          <td>-0.041423</td>
          <td>-0.013144</td>
          <td>-0.019424</td>
          <td>-0.004736</td>
          <td>-0.036479</td>
          <td>0.050680</td>
        </tr>
        <tr>
          <th>3</th>
          <td>-0.081307</td>
          <td>-0.007659</td>
          <td>-0.025897</td>
          <td>0.013765</td>
          <td>0.031358</td>
          <td>-0.052961</td>
          <td>0.049135</td>
          <td>0.029380</td>
          <td>-0.000071</td>
          <td>-0.044642</td>
        </tr>
        <tr>
          <th>4</th>
          <td>0.013139</td>
          <td>-0.032449</td>
          <td>0.032631</td>
          <td>0.005510</td>
          <td>0.021964</td>
          <td>-0.008781</td>
          <td>0.012234</td>
          <td>-0.025295</td>
          <td>-0.037349</td>
          <td>-0.044642</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 134-138

Even after the PCA, the confound will still be present.
This is the case because by default transformers only transform continuous
features (including features without a specified type) and ignore confounds
and categorical variables.

.. GENERATED FROM PYTHON SOURCE LINES 138-141

.. code-block:: default

    df_transformed = preprocess(model, X=X, data=data)
    df_transformed.head()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>pca__pca0</th>
          <th>pca__pca1</th>
          <th>pca__pca2</th>
          <th>pca__pca3</th>
          <th>pca__pca4</th>
          <th>pca__pca5</th>
          <th>pca__pca6</th>
          <th>pca__pca7</th>
          <th>pca__pca8</th>
          <th>sex</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>-0.014051</td>
          <td>0.075715</td>
          <td>0.017395</td>
          <td>-0.012591</td>
          <td>-0.046676</td>
          <td>-0.013408</td>
          <td>0.034497</td>
          <td>-0.008604</td>
          <td>-0.002330</td>
          <td>0.050680</td>
        </tr>
        <tr>
          <th>1</th>
          <td>-0.099883</td>
          <td>-0.062829</td>
          <td>0.014516</td>
          <td>-0.013673</td>
          <td>-0.048058</td>
          <td>0.010254</td>
          <td>-0.004124</td>
          <td>0.024022</td>
          <td>0.002075</td>
          <td>-0.044642</td>
        </tr>
        <tr>
          <th>2</th>
          <td>-0.029015</td>
          <td>0.053253</td>
          <td>0.032477</td>
          <td>-0.061933</td>
          <td>-0.049167</td>
          <td>-0.029565</td>
          <td>0.042031</td>
          <td>-0.001197</td>
          <td>-0.002579</td>
          <td>0.050680</td>
        </tr>
        <tr>
          <th>3</th>
          <td>0.035162</td>
          <td>-0.001324</td>
          <td>-0.106807</td>
          <td>0.028981</td>
          <td>0.020850</td>
          <td>0.023413</td>
          <td>-0.008421</td>
          <td>-0.006566</td>
          <td>-0.003545</td>
          <td>-0.044642</td>
        </tr>
        <tr>
          <th>4</th>
          <td>-0.003951</td>
          <td>-0.025445</td>
          <td>0.000421</td>
          <td>-0.018411</td>
          <td>-0.039692</td>
          <td>0.025022</td>
          <td>-0.043086</td>
          <td>0.002095</td>
          <td>-0.000517</td>
          <td>-0.044642</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 142-147

This means that the resulting Linear Regression can use the deconfounded
features together with the confound to predict the target. However, in the
pipeline creator, the model is only applied to the continuous features.
This means that the confound is not used in the model.
Here we can see that the model is using 9 features.

.. GENERATED FROM PYTHON SOURCE LINES 147-150

.. code-block:: default


    print(len(model.steps[-1][1].model.coef_))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    9




.. GENERATED FROM PYTHON SOURCE LINES 151-153

Lastly, you can also use the confound as a normal feature after confound
removal.

.. GENERATED FROM PYTHON SOURCE LINES 153-168

.. code-block:: default

    creator = PipelineCreator(problem_type="regression", apply_to="continuous")
    creator.add("confound_removal", keep_confounds=True)
    creator.add("pca")
    creator.add("linreg", apply_to="*")

    scores, model = run_cross_validation(
        X=X,
        y="target",
        X_types=X_types,
        data=data,
        model=creator,
        return_estimator="final",
    )
    scores





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    2024-04-29 09:50:39,116 - julearn - INFO - Adding step confound_removal that applies to ColumnTypes<types={'continuous'}; pattern=(?:__:type:__continuous)>
    2024-04-29 09:50:39,117 - julearn - INFO - Setting hyperparameter keep_confounds = True
    2024-04-29 09:50:39,117 - julearn - INFO - Step added
    2024-04-29 09:50:39,117 - julearn - INFO - Adding step pca that applies to ColumnTypes<types={'continuous'}; pattern=(?:__:type:__continuous)>
    2024-04-29 09:50:39,117 - julearn - INFO - Step added
    2024-04-29 09:50:39,117 - julearn - INFO - Adding step linreg that applies to ColumnTypes<types={'*'}; pattern=.*>
    2024-04-29 09:50:39,117 - julearn - INFO - Step added
    2024-04-29 09:50:39,117 - julearn - INFO - ==== Input Data ====
    2024-04-29 09:50:39,117 - julearn - INFO - Using dataframe as input
    2024-04-29 09:50:39,117 - julearn - INFO -      Features: ['age', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'sex']
    2024-04-29 09:50:39,118 - julearn - INFO -      Target: target
    2024-04-29 09:50:39,118 - julearn - INFO -      Expanded features: ['age', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'sex']
    2024-04-29 09:50:39,118 - julearn - INFO -      X_types:{'continuous': ['age', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'], 'confound': ['sex']}
    2024-04-29 09:50:39,119 - julearn - INFO - ====================
    2024-04-29 09:50:39,119 - julearn - INFO - 
    2024-04-29 09:50:39,120 - julearn - INFO - = Model Parameters =
    2024-04-29 09:50:39,120 - julearn - INFO - ====================
    2024-04-29 09:50:39,120 - julearn - INFO - 
    2024-04-29 09:50:39,120 - julearn - INFO - = Data Information =
    2024-04-29 09:50:39,120 - julearn - INFO -      Problem type: regression
    2024-04-29 09:50:39,120 - julearn - INFO -      Number of samples: 442
    2024-04-29 09:50:39,120 - julearn - INFO -      Number of features: 10
    2024-04-29 09:50:39,120 - julearn - INFO - ====================
    2024-04-29 09:50:39,120 - julearn - INFO - 
    2024-04-29 09:50:39,121 - julearn - INFO -      Target type: float64
    2024-04-29 09:50:39,121 - julearn - INFO - Using outer CV scheme KFold(n_splits=5, random_state=None, shuffle=False)
    /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.
      warnings.warn(
    2024-04-29 09:50:39,300 - julearn - INFO - Fitting final model


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>fit_time</th>
          <th>score_time</th>
          <th>test_score</th>
          <th>n_train</th>
          <th>n_test</th>
          <th>repeat</th>
          <th>fold</th>
          <th>cv_mdsum</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>0.026313</td>
          <td>0.009253</td>
          <td>0.429556</td>
          <td>353</td>
          <td>89</td>
          <td>0</td>
          <td>0</td>
          <td>b10eef89b4192178d482d7a1587a248a</td>
        </tr>
        <tr>
          <th>1</th>
          <td>0.024024</td>
          <td>0.009196</td>
          <td>0.522599</td>
          <td>353</td>
          <td>89</td>
          <td>0</td>
          <td>1</td>
          <td>b10eef89b4192178d482d7a1587a248a</td>
        </tr>
        <tr>
          <th>2</th>
          <td>0.025104</td>
          <td>0.009068</td>
          <td>0.482681</td>
          <td>354</td>
          <td>88</td>
          <td>0</td>
          <td>2</td>
          <td>b10eef89b4192178d482d7a1587a248a</td>
        </tr>
        <tr>
          <th>3</th>
          <td>0.024702</td>
          <td>0.009425</td>
          <td>0.426498</td>
          <td>354</td>
          <td>88</td>
          <td>0</td>
          <td>3</td>
          <td>b10eef89b4192178d482d7a1587a248a</td>
        </tr>
        <tr>
          <th>4</th>
          <td>0.024089</td>
          <td>0.009011</td>
          <td>0.550248</td>
          <td>354</td>
          <td>88</td>
          <td>0</td>
          <td>4</td>
          <td>b10eef89b4192178d482d7a1587a248a</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 169-175

As you can see the confound is now used in the linear regression model.
This is the case because we set the ``apply_to`` argument of the ``linreg``
step to ``*``. This means that the step will be applied to all features
(including confounds and categorical variables).
Here we can see that the model is using 10 features (9 deconfounded features
and the confound).

.. GENERATED FROM PYTHON SOURCE LINES 175-176

.. code-block:: default

    print(len(model.steps[-1][1].model.coef_))




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    10





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 0.693 seconds)


.. _sphx_glr_download_auto_examples_04_confounds_run_return_confounds.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: run_return_confounds.py <run_return_confounds.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: run_return_confounds.ipynb <run_return_confounds.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
