{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Simple Model Comparison\n\nThis example uses the 'iris' dataset and performs binary classifications\nusing different models. At the end, it compares the performance of the models\nusing different scoring functions and performs a statistical test to assess\nwhether the difference in performance is significant.\n\n.. include:: ../../links.inc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Federico Raimondo <f.raimondo@fz-juelich.de>\n#\n# License: AGPL\n\nfrom seaborn import load_dataset\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom julearn import run_cross_validation\nfrom julearn.utils import configure_logging\nfrom julearn.stats.corrected_ttest import corrected_ttest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the logging level to info to see extra information\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "configure_logging(level=\"INFO\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_iris = load_dataset(\"iris\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset has three kind of species. We will keep two to perform a binary\nclassification.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_iris = df_iris[df_iris[\"species\"].isin([\"versicolor\", \"virginica\"])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As features, we will use the sepal length, width and petal length.\nWe will try to predict the species.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X = [\"sepal_length\", \"sepal_width\", \"petal_length\"]\ny = \"species\"\nscores = run_cross_validation(\n    X=X,\n    y=y,\n    data=df_iris,\n    model=\"svm\",\n    problem_type=\"classification\",\n    preprocess=\"zscore\",\n)\n\nprint(scores[\"test_score\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Additionally, we can choose to assess the performance of the model using\ndifferent scoring functions.\n\nFor example, we might have an unbalanced dataset:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_unbalanced = df_iris[20:]  # drop the first 20 versicolor samples\nprint(df_unbalanced[\"species\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So we will choose to use the `balanced_accuracy` and `roc_auc` metrics.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scoring = [\"balanced_accuracy\", \"roc_auc\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since we are comparing the performance of different models, we will need\nto use the same random seed to split the data in the same way.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we will use a default SVM model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores1 = run_cross_validation(\n    X=X,\n    y=y,\n    data=df_unbalanced,\n    model=\"svm\",\n    preprocess=\"zscore\",\n    problem_type=\"classification\",\n    scoring=scoring,\n    cv=cv,\n)\n\nscores1[\"model\"] = \"svm\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Second we will use a default Random Forest model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores2 = run_cross_validation(\n    X=X,\n    y=y,\n    data=df_unbalanced,\n    model=\"rf\",\n    preprocess=\"zscore\",\n    problem_type=\"classification\",\n    scoring=scoring,\n    cv=cv,\n)\n\nscores2[\"model\"] = \"rf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The third model will be a SVM with a linear kernel.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores3 = run_cross_validation(\n    X=X,\n    y=y,\n    data=df_unbalanced,\n    model=\"svm\",\n    model_params={\"svm__kernel\": \"linear\"},\n    preprocess=\"zscore\",\n    problem_type=\"classification\",\n    scoring=scoring,\n    cv=cv,\n)\n\nscores3[\"model\"] = \"svm_linear\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now compare the performance of the models using corrected statistics\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stats_df = corrected_ttest(scores1, scores2, scores3)\nprint(stats_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. rst-class:: hidden\n  This block is hidden in the documentation. This files are used to generate\n  the plots in the documentation. (not working for now)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The following lines are only meant for the documentation to work and not\n# needed for the example to run. This will be removed as soon as sphix-gallery\n# is able to hide code blocks.\nscores1.to_csv(\"/tmp/scores1.csv\")\nscores2.to_csv(\"/tmp/scores2.csv\")\nscores3.to_csv(\"/tmp/scores3.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also plot the performance of the models using the Julearn Score Viewer\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from julearn.viz import plot_scores\npanel = plot_scores(scores1, scores2, scores3)\n# panel.show() \n# uncomment the previous line show the plot\n# read the documentation for more information\n#  https://panel.holoviz.org/getting_started/build_app.html#deploying-panels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is how the plot looks like.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The plot is interactive. You can zoom in and out, and hover over.\n   However, buttons will not work in this documentation.</p></div>\n\n.. bokeh-plot::\n   :source-position: none\n\n   from julearn.viz import plot_scores\n   from bokeh.io import output_notebook, show\n   import pandas as pd\n   output_notebook()\n   scores1 = pd.read_csv(\"/tmp/scores1.csv\")\n   scores2 = pd.read_csv(\"/tmp/scores2.csv\")\n   scores3 = pd.read_csv(\"/tmp/scores3.csv\")\n   panel = plot_scores(scores1, scores2, scores3, width=600)\n   show(panel.get_root())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}