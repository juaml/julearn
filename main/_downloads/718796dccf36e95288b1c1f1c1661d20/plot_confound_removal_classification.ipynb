{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Confound Removal (model comparison)\n\nThis example uses the 'iris' dataset, performs simple binary classification\nwith and without confound removal using a Random Forest classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Shammi More <s.more@fz-juelich.de>\n#          Federico Raimondo <f.raimondo@fz-juelich.de>\n#\n# License: AGPL\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom seaborn import load_dataset\n\nfrom julearn import run_cross_validation\nfrom julearn.utils import configure_logging\nfrom julearn.model_selection import StratifiedBootstrap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the logging level to info to see extra information\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "configure_logging(level='INFO')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "load the iris data from seaborn\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_iris = load_dataset('iris')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset has three kind of species. We will keep two to perform a binary\nclassification.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_iris = df_iris[df_iris['species'].isin(['versicolor', 'virginica'])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As features, we will use the sepal length, width and petal length and use\npetal width as confound.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X = ['sepal_length', 'sepal_width', 'petal_length']\ny = 'species'\nconfound = 'petal_width'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Doing hypothesis testing in ML is not that simple. If we were to used\nclassical frequentist statistics, we have the problem that using cross\nvalidation, the samples are not independent and the population (train + test)\nis always the same.\n\nIf we want to compare two models, an alternative is to contrast, for each\nfold, the performance gap between the models. If we combine that approach\nwith bootstrapping, we can then compare the confidence intervals of the\ndifference. If the 95% CI is above 0 (or below), we can claim that the models\nare different with p < 0.05.\n\nLets use a bootstrap CV. For time purposes we do 20 iterations, change the\nnumber of bootstrap iterations to at least 2000 for a valid test.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_bootstrap = 20\nn_elements = len(df_iris)\ncv = StratifiedBootstrap(n_splits=n_bootstrap, test_size=.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we will train a model without performing confound removal on features\nNote: confounds=None by default\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores_ncr = run_cross_validation(\n    X=X, y=y, data=df_iris, model='rf', cv=cv, preprocess_X='zscore',\n    scoring=['accuracy', 'roc_auc'], return_estimator='cv', seed=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we train a model after performing confound removal on the features\nNote: we initialize the CV again to use the same folds as before\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cv = StratifiedBootstrap(n_splits=n_bootstrap, test_size=.3, random_state=42)\nscores_cr = run_cross_validation(\n    X=X, y=y, confounds=confound, data=df_iris, model='rf',\n    preprocess_X='remove_confound', preprocess_confounds='zscore', cv=cv,\n    scoring=['accuracy', 'roc_auc'], return_estimator='cv', seed=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can compare the accuracies. We can combine the two outputs as\npandas dataframes\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores_ncr['confounds'] = 'Not Removed'\nscores_cr['confounds'] = 'Removed'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we convert the metrics to a column for easier seaborn plotting (convert\nto long format)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "index = ['fold', 'confounds']\nscorings = ['test_accuracy', 'test_roc_auc']\n\ndf_ncr_metrics = scores_ncr.set_index(index)[scorings].stack()\ndf_ncr_metrics.index.names = ['fold', 'confounds', 'metric']\ndf_ncr_metrics.name = 'value'\n\ndf_cr_metrics = scores_cr.set_index(index)[scorings].stack()\ndf_cr_metrics.index.names = ['fold', 'confounds', 'metric']\ndf_cr_metrics.name = 'value'\n\ndf_metrics = pd.concat((df_ncr_metrics, df_cr_metrics))\n\ndf_metrics = df_metrics.reset_index()\nprint(df_metrics.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And finally plot the results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sns.catplot(x='confounds', y='value', col='metric', data=df_metrics,\n            kind='swarm')\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "While this plot allows us to see the mean performance values and compare\nthem, these samples are paired. In order to see if there is a systematic\ndifference, we need to check the distribution of differeces between the\nthe models.\n\nFirst we remove the column \"confounds\" from the index and make the difference\nbetween the metrics\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_cr_metrics = df_cr_metrics.reset_index().set_index(['fold', 'metric'])\ndf_ncr_metrics = df_ncr_metrics.reset_index().set_index(['fold', 'metric'])\n\ndf_diff_metrics = df_ncr_metrics['value'] - df_cr_metrics['value']\ndf_diff_metrics = df_diff_metrics.reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can finally plot the difference, setting the whiskers of the box plot\nat 2.5 and 97.5 to see the 95% CI.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x='metric', y='value', data=df_diff_metrics.reset_index(),\n            whis=[2.5, 97.5])\nplt.axhline(0, color='k', ls=':')\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that while it seems that the accuracy and ROC AUC scores are\nhigher when confounds are not removed. We can not really claim (using this\ntest), that the models are different in terms of these metrics.\n\nMaybe the percentiles will be more accuracy with the proper amount of\nbootstrap iterations?\n\n\nBut the main point of confound removal is for interpretability. Lets see\nif there is a change in the feature importances.\n\nFirst, we need to collect the feature importances for each model, for each\nfold.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ncr_fi = []\nfor i_fold, estimator in enumerate(scores_ncr['estimator']):\n    this_importances = pd.DataFrame({\n        'feature': [x.replace('_', ' ') for x in X],\n        'importance': estimator['rf'].feature_importances_,\n        'confounds': 'Not Removed',\n        'fold': i_fold\n    })\n    ncr_fi.append(this_importances)\nncr_fi = pd.concat(ncr_fi)\n\ncr_fi = []\nfor i_fold, estimator in enumerate(scores_cr['estimator']):\n    this_importances = pd.DataFrame({\n        'feature': [x.replace('_', ' ') for x in X],\n        'importance': estimator['rf'].feature_importances_,\n        'confounds': 'Removed',\n        'fold': i_fold\n    })\n    cr_fi.append(this_importances)\ncr_fi = pd.concat(cr_fi)\n\nfeature_importance = pd.concat([cr_fi, ncr_fi])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now plot the importances\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sns.catplot(x='feature', y='importance', hue='confounds', dodge=True,\n            data=feature_importance, kind='swarm', s=3)\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And check the differences in importances. We can now see that there is\na difference in importances.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "diff_fi = (cr_fi.set_index(['feature', 'fold'])['importance'] -\n           ncr_fi.set_index(['feature', 'fold'])['importance'])\nsns.boxplot(x='importance', y='feature', data=diff_fi.reset_index(),\n            whis=[2.5, 97.5])\nplt.axvline(0, color='k', ls=':')\nplt.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}