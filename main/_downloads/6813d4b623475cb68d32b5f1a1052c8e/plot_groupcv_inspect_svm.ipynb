{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Inspecting SVM models\n\nThis example uses the 'fmri' dataset, performs simple binary classification\nusing a Support Vector Machine classifier and analyse the model.\n\n\n## References\nWaskom, M.L., Frank, M.C., Wagner, A.D. (2016). Adaptive engagement of\ncognitive control in context-dependent decision-making. Cerebral Cortex.\n\n\n.. include:: ../../links.inc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Federico Raimondo <f.raimondo@fz-juelich.de>\n#\n# License: AGPL\nimport numpy as np\n\nfrom sklearn.model_selection import GroupShuffleSplit\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom seaborn import load_dataset\n\nfrom julearn import run_cross_validation\nfrom julearn.utils import configure_logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the logging level to info to see extra information\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "configure_logging(level='INFO')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dealing with Cross-Validation techinques\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_fmri = load_dataset('fmri')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, lets get some information on what the dataset has:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(df_fmri.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From this information, we can infer that it is an fMRI study in which there\nwere several subjects, timepoints, events and signal extracted from several\nbrain regions.\n\nLets check how many kinds of each we have.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(df_fmri['event'].unique())\nprint(df_fmri['region'].unique())\nprint(sorted(df_fmri['timepoint'].unique()))\nprint(df_fmri['subject'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have data from parietal and frontal regions during 2 types of events\n(*cue* and *stim*) during 18 timepoints and for 14 subjects.\nLets see how many samples we have for each condition\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(df_fmri.groupby(['subject', 'timepoint', 'event', 'region']).count())\nprint(np.unique(df_fmri.groupby(\n    ['subject', 'timepoint', 'event', 'region']).count().values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have exactly one value per condition.\n\nLets try to build a model, that given both parietal and frontal signal,\npredicts if the event was a *cue* or a *stim*.\n\nFirst we define our X and y variables.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X = ['parietal', 'frontal']\ny = 'event'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order for this to work, both *parietal* and *frontal* must be columns.\nWe need to *pivot* the table.\n\nThe values of *region* will be the columns. The column *signal* will be the\nvalues. And the columns *subject*, *timepoint* and *event* will be the index\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_fmri = df_fmri.pivot(\n    index=['subject', 'timepoint', 'event'],\n    columns='region',\n    values='signal')\n\ndf_fmri = df_fmri.reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use a Support Vector Machine.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores = run_cross_validation(X=X, y=y, preprocess_X='zscore', data=df_fmri,\n                              model='svm')\n\nprint(scores['test_score'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This results indicate that we can decode the kind of event by looking at\nthe *parietal* and *frontal* signal. However, that claim is true only if we\nhave some data from the same subject already acquired.\n\nThe problem is that we split the data randomly into 5 folds (default, see\n:func:`.run_cross_validation`). This means that data from one subject could\nbe both in the training and the testing set. If this is the case, then the\nmodel can learn the subjects' specific characteristics and apply it to the\ntesting set. Thus, it is not true that we can decode it for an unseen\nsubject, but for an unseen timepoint for a subject that for whom we already\nhave data.\n\nTo test for unseen subject, we need to make sure that all the data from each\nsubject is either on the training or the testing set, but not in both.\n\nWe can use scikit-learn's GroupShuffleSplit (see `Cross Validation`_).\nAnd specify which is the grouping column using the `group` parameter.\n\nBy setting `return_estimator='final'`, the :func:`.run_cross_validation`\nfunction return the estimator fitted with all the data. We will use this\nlater to do some analysis.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cv = GroupShuffleSplit(n_splits=5, test_size=0.5, random_state=42)\n\nscores, model = run_cross_validation(\n    X=X, y=y, data=df_fmri, model='svm', preprocess_X='zscore', cv=cv,\n    groups='subject', return_estimator='final')\nprint(scores['test_score'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After testing on independent subjects, we can now claim that given a new\nsubject, we can predict the kind of event.\n\nLets do some visualization on how these two features interact and what\nthe preprocessing part of the model does.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\nsns.scatterplot(x='parietal', y='frontal', hue='event', data=df_fmri,\n                ax=axes[0], s=5)\naxes[0].set_title('Raw data')\n\npre_X, pre_y = model.preprocess(df_fmri[X], df_fmri[y])\npre_df = pre_X.join(pre_y)\nsns.scatterplot(x='parietal', y='frontal', hue='event', data=pre_df,\n                ax=axes[1], s=5)\naxes[1].set_title('Preprocessed data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, the preprocessing is nothing more than a `Standard Scaler`_.\n\nIt seems that the data is not quite linearly separable. Lets now visualize\nhow the SVM does this complex task.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clf = model['svm']\nax = sns.scatterplot(x='parietal', y='frontal', hue='event', data=pre_df, s=5)\n\nxlim = ax.get_xlim()\nylim = ax.get_ylim()\n\n# create grid to evaluate model\nxx = np.linspace(xlim[0], xlim[1], 30)\nyy = np.linspace(ylim[0], ylim[1], 30)\nYY, XX = np.meshgrid(yy, xx)\nxy = np.vstack([XX.ravel(), YY.ravel()]).T\nZ = clf.decision_function(xy).reshape(XX.shape)\na = ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=0.5, linestyles=['-'])\nax.set_title('Preprocessed data with SVM decision function boundaries')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}